{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGvruWWtaKkhE1/utNim+e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jay-kanakia/GenAI/blob/main/03_Pytorch_training_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Pn80f6RhMFYh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "8jGT4vF6OXZB",
        "outputId": "4f612e0b-de5b-40df-a7f1-315d7d9eef04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50a2e0fc-278e-409c-b1e2-ecbe77b6134c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50a2e0fc-278e-409c-b1e2-ecbe77b6134c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50a2e0fc-278e-409c-b1e2-ecbe77b6134c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50a2e0fc-278e-409c-b1e2-ecbe77b6134c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['id','Unnamed: 32'],inplace=True)"
      ],
      "metadata": {
        "id": "4hGE4ZrfOYPv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "TCYIDzR6OpKP",
        "outputId": "96166876-aa7a-4644-fc19-c8a56b454b2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "554         B        12.88         28.92           82.50      514.3   \n",
              "98          B        11.60         12.84           74.34      412.6   \n",
              "452         B        12.00         28.23           76.77      442.5   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "554          0.08123           0.05824         0.06195              0.02343   \n",
              "98           0.08983           0.07525         0.04196              0.03350   \n",
              "452          0.08437           0.06450         0.04055              0.01945   \n",
              "\n",
              "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "554         0.1566  ...         13.89          35.74            88.84   \n",
              "98          0.1620  ...         13.06          17.16            82.96   \n",
              "452         0.1615  ...         13.09          37.88            85.07   \n",
              "\n",
              "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "554       595.7            0.1227             0.1620           0.2439   \n",
              "98        512.5            0.1431             0.1851           0.1922   \n",
              "452       523.7            0.1208             0.1856           0.1811   \n",
              "\n",
              "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "554               0.06493          0.2372                  0.07242  \n",
              "98                0.08449          0.2772                  0.08756  \n",
              "452               0.07116          0.2447                  0.08194  \n",
              "\n",
              "[3 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28cf59a7-c3de-4925-b9b1-693cfd65688f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>B</td>\n",
              "      <td>12.88</td>\n",
              "      <td>28.92</td>\n",
              "      <td>82.50</td>\n",
              "      <td>514.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.05824</td>\n",
              "      <td>0.06195</td>\n",
              "      <td>0.02343</td>\n",
              "      <td>0.1566</td>\n",
              "      <td>...</td>\n",
              "      <td>13.89</td>\n",
              "      <td>35.74</td>\n",
              "      <td>88.84</td>\n",
              "      <td>595.7</td>\n",
              "      <td>0.1227</td>\n",
              "      <td>0.1620</td>\n",
              "      <td>0.2439</td>\n",
              "      <td>0.06493</td>\n",
              "      <td>0.2372</td>\n",
              "      <td>0.07242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>B</td>\n",
              "      <td>11.60</td>\n",
              "      <td>12.84</td>\n",
              "      <td>74.34</td>\n",
              "      <td>412.6</td>\n",
              "      <td>0.08983</td>\n",
              "      <td>0.07525</td>\n",
              "      <td>0.04196</td>\n",
              "      <td>0.03350</td>\n",
              "      <td>0.1620</td>\n",
              "      <td>...</td>\n",
              "      <td>13.06</td>\n",
              "      <td>17.16</td>\n",
              "      <td>82.96</td>\n",
              "      <td>512.5</td>\n",
              "      <td>0.1431</td>\n",
              "      <td>0.1851</td>\n",
              "      <td>0.1922</td>\n",
              "      <td>0.08449</td>\n",
              "      <td>0.2772</td>\n",
              "      <td>0.08756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>B</td>\n",
              "      <td>12.00</td>\n",
              "      <td>28.23</td>\n",
              "      <td>76.77</td>\n",
              "      <td>442.5</td>\n",
              "      <td>0.08437</td>\n",
              "      <td>0.06450</td>\n",
              "      <td>0.04055</td>\n",
              "      <td>0.01945</td>\n",
              "      <td>0.1615</td>\n",
              "      <td>...</td>\n",
              "      <td>13.09</td>\n",
              "      <td>37.88</td>\n",
              "      <td>85.07</td>\n",
              "      <td>523.7</td>\n",
              "      <td>0.1208</td>\n",
              "      <td>0.1856</td>\n",
              "      <td>0.1811</td>\n",
              "      <td>0.07116</td>\n",
              "      <td>0.2447</td>\n",
              "      <td>0.08194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28cf59a7-c3de-4925-b9b1-693cfd65688f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28cf59a7-c3de-4925-b9b1-693cfd65688f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28cf59a7-c3de-4925-b9b1-693cfd65688f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1dMHGBHUy0i",
        "outputId": "1dbe2afa-f174-42cd-f01b-6ffc18425e1c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h6QePzWrU0Vh",
        "outputId": "8e511fd6-075f-4ddd-b457-6de7be0ff3f4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis                  0\n",
              "radius_mean                0\n",
              "texture_mean               0\n",
              "perimeter_mean             0\n",
              "area_mean                  0\n",
              "smoothness_mean            0\n",
              "compactness_mean           0\n",
              "concavity_mean             0\n",
              "concave points_mean        0\n",
              "symmetry_mean              0\n",
              "fractal_dimension_mean     0\n",
              "radius_se                  0\n",
              "texture_se                 0\n",
              "perimeter_se               0\n",
              "area_se                    0\n",
              "smoothness_se              0\n",
              "compactness_se             0\n",
              "concavity_se               0\n",
              "concave points_se          0\n",
              "symmetry_se                0\n",
              "fractal_dimension_se       0\n",
              "radius_worst               0\n",
              "texture_worst              0\n",
              "perimeter_worst            0\n",
              "area_worst                 0\n",
              "smoothness_worst           0\n",
              "compactness_worst          0\n",
              "concavity_worst            0\n",
              "concave points_worst       0\n",
              "symmetry_worst             0\n",
              "fractal_dimension_worst    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>diagnosis</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,1:]\n",
        "y=df.iloc[:,0]\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X_train_scaled=ss.fit_transform(X_train)\n",
        "X_test_scaled=ss.transform(X_test)\n",
        "\n",
        "le=LabelEncoder()\n",
        "y_train_transformed=le.fit_transform(y_train)\n",
        "y_test_transformed=le.transform(y_test)"
      ],
      "metadata": {
        "id": "ggkh3PWJOsmg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor=torch.from_numpy(X_train_scaled).float()\n",
        "X_test_tensor=torch.from_numpy(X_test_scaled).float()\n",
        "y_train_tensor=torch.from_numpy(y_train_transformed).float()\n",
        "y_test_tensor=torch.from_numpy(y_test_transformed).float()"
      ],
      "metadata": {
        "id": "hekQagANPsMh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uluu9qx3erhX",
        "outputId": "fa7b7742-d910-45dd-de53-132ee12efe48"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcIabkLcexNm",
        "outputId": "9d0b7a03-6a26-44cb-90c0-1768bb7c905b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2yNj1fckbI",
        "outputId": "345be909-c587-4be5-c325-a91ec861bd1f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([455, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleNN():\n",
        "\n",
        "  def __init__(self,X):\n",
        "    self.weights=torch.rand(X.shape[1],1,dtype=torch.float32,requires_grad=True)\n",
        "    self.bias=torch.zeros(1,dtype=torch.float32,requires_grad=True)\n",
        "\n",
        "  def forward(self,X):\n",
        "    z=torch.matmul(X,self.weights)+self.bias\n",
        "    y_pred=torch.sigmoid(z)\n",
        "    return y_pred\n",
        "\n",
        "  def loss_function(self, y_pred, y):\n",
        "    # Clamp predictions to avoid log(0)\n",
        "    epsilon = 1e-7\n",
        "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = -(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred)).mean()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "oQjpC4TyRbVZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "epochs=2000\n",
        "\n",
        "model=MySimpleNN(X_train_tensor)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  y_pred=model.forward(X_train_tensor)\n",
        "\n",
        "  loss=model.loss_function(y_pred,y_train_tensor)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.weights -= learning_rate * model.weights.grad\n",
        "    model.bias    -= learning_rate * model.bias.grad\n",
        "\n",
        "    # Zero gradients after update\n",
        "    model.weights.grad.zero_()\n",
        "    model.bias.grad.zero_()\n",
        "\n",
        "  print(f\"for epoch {epoch+1} loss is {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iFGpnaCTEuJ",
        "outputId": "4d209b44-5fef-4a4b-eaeb-3265e1733851"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 1 loss is 3.104005813598633\n",
            "for epoch 2 loss is 3.088681221008301\n",
            "for epoch 3 loss is 3.073618173599243\n",
            "for epoch 4 loss is 3.0583548545837402\n",
            "for epoch 5 loss is 3.04158616065979\n",
            "for epoch 6 loss is 3.0269503593444824\n",
            "for epoch 7 loss is 3.010054111480713\n",
            "for epoch 8 loss is 2.9946956634521484\n",
            "for epoch 9 loss is 2.9800565242767334\n",
            "for epoch 10 loss is 2.9634108543395996\n",
            "for epoch 11 loss is 2.9487664699554443\n",
            "for epoch 12 loss is 2.9323959350585938\n",
            "for epoch 13 loss is 2.916835308074951\n",
            "for epoch 14 loss is 2.900510311126709\n",
            "for epoch 15 loss is 2.8858094215393066\n",
            "for epoch 16 loss is 2.869412422180176\n",
            "for epoch 17 loss is 2.853649377822876\n",
            "for epoch 18 loss is 2.8378214836120605\n",
            "for epoch 19 loss is 2.8220064640045166\n",
            "for epoch 20 loss is 2.8051443099975586\n",
            "for epoch 21 loss is 2.7891716957092285\n",
            "for epoch 22 loss is 2.772996425628662\n",
            "for epoch 23 loss is 2.756586790084839\n",
            "for epoch 24 loss is 2.7392709255218506\n",
            "for epoch 25 loss is 2.7230310440063477\n",
            "for epoch 26 loss is 2.7058095932006836\n",
            "for epoch 27 loss is 2.6889922618865967\n",
            "for epoch 28 loss is 2.6721251010894775\n",
            "for epoch 29 loss is 2.655505418777466\n",
            "for epoch 30 loss is 2.636746883392334\n",
            "for epoch 31 loss is 2.619715929031372\n",
            "for epoch 32 loss is 2.603121280670166\n",
            "for epoch 33 loss is 2.5849609375\n",
            "for epoch 34 loss is 2.566793918609619\n",
            "for epoch 35 loss is 2.5489742755889893\n",
            "for epoch 36 loss is 2.532351016998291\n",
            "for epoch 37 loss is 2.514496088027954\n",
            "for epoch 38 loss is 2.4956796169281006\n",
            "for epoch 39 loss is 2.477612257003784\n",
            "for epoch 40 loss is 2.460204601287842\n",
            "for epoch 41 loss is 2.442840576171875\n",
            "for epoch 42 loss is 2.4253320693969727\n",
            "for epoch 43 loss is 2.4069530963897705\n",
            "for epoch 44 loss is 2.389561414718628\n",
            "for epoch 45 loss is 2.37203311920166\n",
            "for epoch 46 loss is 2.354401111602783\n",
            "for epoch 47 loss is 2.337048292160034\n",
            "for epoch 48 loss is 2.3190925121307373\n",
            "for epoch 49 loss is 2.3013155460357666\n",
            "for epoch 50 loss is 2.2837135791778564\n",
            "for epoch 51 loss is 2.2661619186401367\n",
            "for epoch 52 loss is 2.2485153675079346\n",
            "for epoch 53 loss is 2.2310760021209717\n",
            "for epoch 54 loss is 2.213412046432495\n",
            "for epoch 55 loss is 2.1950509548187256\n",
            "for epoch 56 loss is 2.17756724357605\n",
            "for epoch 57 loss is 2.1601920127868652\n",
            "for epoch 58 loss is 2.142852544784546\n",
            "for epoch 59 loss is 2.1240904331207275\n",
            "for epoch 60 loss is 2.106809616088867\n",
            "for epoch 61 loss is 2.089733362197876\n",
            "for epoch 62 loss is 2.072237253189087\n",
            "for epoch 63 loss is 2.0551695823669434\n",
            "for epoch 64 loss is 2.037292242050171\n",
            "for epoch 65 loss is 2.0200955867767334\n",
            "for epoch 66 loss is 2.0030288696289062\n",
            "for epoch 67 loss is 1.9856137037277222\n",
            "for epoch 68 loss is 1.968687653541565\n",
            "for epoch 69 loss is 1.9515714645385742\n",
            "for epoch 70 loss is 1.9345893859863281\n",
            "for epoch 71 loss is 1.9173532724380493\n",
            "for epoch 72 loss is 1.9004465341567993\n",
            "for epoch 73 loss is 1.8834376335144043\n",
            "for epoch 74 loss is 1.8665432929992676\n",
            "for epoch 75 loss is 1.8487396240234375\n",
            "for epoch 76 loss is 1.832011342048645\n",
            "for epoch 77 loss is 1.8153507709503174\n",
            "for epoch 78 loss is 1.7988146543502808\n",
            "for epoch 79 loss is 1.7818224430084229\n",
            "for epoch 80 loss is 1.7654632329940796\n",
            "for epoch 81 loss is 1.7484937906265259\n",
            "for epoch 82 loss is 1.7317150831222534\n",
            "for epoch 83 loss is 1.7151117324829102\n",
            "for epoch 84 loss is 1.6984024047851562\n",
            "for epoch 85 loss is 1.681830883026123\n",
            "for epoch 86 loss is 1.6642365455627441\n",
            "for epoch 87 loss is 1.6478965282440186\n",
            "for epoch 88 loss is 1.630630612373352\n",
            "for epoch 89 loss is 1.614332914352417\n",
            "for epoch 90 loss is 1.5976519584655762\n",
            "for epoch 91 loss is 1.5811322927474976\n",
            "for epoch 92 loss is 1.5648399591445923\n",
            "for epoch 93 loss is 1.548336148262024\n",
            "for epoch 94 loss is 1.5321509838104248\n",
            "for epoch 95 loss is 1.5161842107772827\n",
            "for epoch 96 loss is 1.5003715753555298\n",
            "for epoch 97 loss is 1.484727382659912\n",
            "for epoch 98 loss is 1.4690148830413818\n",
            "for epoch 99 loss is 1.453515887260437\n",
            "for epoch 100 loss is 1.4382209777832031\n",
            "for epoch 101 loss is 1.4229464530944824\n",
            "for epoch 102 loss is 1.4079067707061768\n",
            "for epoch 103 loss is 1.3930110931396484\n",
            "for epoch 104 loss is 1.3782140016555786\n",
            "for epoch 105 loss is 1.3635969161987305\n",
            "for epoch 106 loss is 1.3490691184997559\n",
            "for epoch 107 loss is 1.3347846269607544\n",
            "for epoch 108 loss is 1.3205702304840088\n",
            "for epoch 109 loss is 1.3065906763076782\n",
            "for epoch 110 loss is 1.2927329540252686\n",
            "for epoch 111 loss is 1.2790324687957764\n",
            "for epoch 112 loss is 1.265506625175476\n",
            "for epoch 113 loss is 1.2521494626998901\n",
            "for epoch 114 loss is 1.238964557647705\n",
            "for epoch 115 loss is 1.2259457111358643\n",
            "for epoch 116 loss is 1.213100790977478\n",
            "for epoch 117 loss is 1.200430989265442\n",
            "for epoch 118 loss is 1.18794584274292\n",
            "for epoch 119 loss is 1.1756370067596436\n",
            "for epoch 120 loss is 1.1635138988494873\n",
            "for epoch 121 loss is 1.151569128036499\n",
            "for epoch 122 loss is 1.1398189067840576\n",
            "for epoch 123 loss is 1.1282471418380737\n",
            "for epoch 124 loss is 1.1168711185455322\n",
            "for epoch 125 loss is 1.105678915977478\n",
            "for epoch 126 loss is 1.0946825742721558\n",
            "for epoch 127 loss is 1.0838788747787476\n",
            "for epoch 128 loss is 1.0732694864273071\n",
            "for epoch 129 loss is 1.06285560131073\n",
            "for epoch 130 loss is 1.0526360273361206\n",
            "for epoch 131 loss is 1.0426148176193237\n",
            "for epoch 132 loss is 1.0327908992767334\n",
            "for epoch 133 loss is 1.02316415309906\n",
            "for epoch 134 loss is 1.013737440109253\n",
            "for epoch 135 loss is 1.0045082569122314\n",
            "for epoch 136 loss is 0.995478630065918\n",
            "for epoch 137 loss is 0.9866472482681274\n",
            "for epoch 138 loss is 0.9780145287513733\n",
            "for epoch 139 loss is 0.9695802330970764\n",
            "for epoch 140 loss is 0.9613434076309204\n",
            "for epoch 141 loss is 0.9533044099807739\n",
            "for epoch 142 loss is 0.9454615712165833\n",
            "for epoch 143 loss is 0.9378137588500977\n",
            "for epoch 144 loss is 0.9303606152534485\n",
            "for epoch 145 loss is 0.9231007099151611\n",
            "for epoch 146 loss is 0.9160321354866028\n",
            "for epoch 147 loss is 0.9091538786888123\n",
            "for epoch 148 loss is 0.902463972568512\n",
            "for epoch 149 loss is 0.8959605097770691\n",
            "for epoch 150 loss is 0.8896417021751404\n",
            "for epoch 151 loss is 0.8835052251815796\n",
            "for epoch 152 loss is 0.8775489330291748\n",
            "for epoch 153 loss is 0.8717700839042664\n",
            "for epoch 154 loss is 0.8661665916442871\n",
            "for epoch 155 loss is 0.860735297203064\n",
            "for epoch 156 loss is 0.8554735779762268\n",
            "for epoch 157 loss is 0.8503786325454712\n",
            "for epoch 158 loss is 0.8454471230506897\n",
            "for epoch 159 loss is 0.8406761884689331\n",
            "for epoch 160 loss is 0.8360626697540283\n",
            "for epoch 161 loss is 0.8316030502319336\n",
            "for epoch 162 loss is 0.827294111251831\n",
            "for epoch 163 loss is 0.823132336139679\n",
            "for epoch 164 loss is 0.8191141486167908\n",
            "for epoch 165 loss is 0.8152362108230591\n",
            "for epoch 166 loss is 0.8114950060844421\n",
            "for epoch 167 loss is 0.8078866600990295\n",
            "for epoch 168 loss is 0.8044075965881348\n",
            "for epoch 169 loss is 0.8010543584823608\n",
            "for epoch 170 loss is 0.7978231906890869\n",
            "for epoch 171 loss is 0.7947104573249817\n",
            "for epoch 172 loss is 0.7917125821113586\n",
            "for epoch 173 loss is 0.7888259291648865\n",
            "for epoch 174 loss is 0.7860469818115234\n",
            "for epoch 175 loss is 0.783372163772583\n",
            "for epoch 176 loss is 0.7807979583740234\n",
            "for epoch 177 loss is 0.7783210277557373\n",
            "for epoch 178 loss is 0.7759379148483276\n",
            "for epoch 179 loss is 0.7736453413963318\n",
            "for epoch 180 loss is 0.7714399099349976\n",
            "for epoch 181 loss is 0.7693184614181519\n",
            "for epoch 182 loss is 0.7672778964042664\n",
            "for epoch 183 loss is 0.7653152346611023\n",
            "for epoch 184 loss is 0.7634273767471313\n",
            "for epoch 185 loss is 0.7616113424301147\n",
            "for epoch 186 loss is 0.7598644495010376\n",
            "for epoch 187 loss is 0.7581839561462402\n",
            "for epoch 188 loss is 0.7565669417381287\n",
            "for epoch 189 loss is 0.7550110816955566\n",
            "for epoch 190 loss is 0.7535136938095093\n",
            "for epoch 191 loss is 0.7520725727081299\n",
            "for epoch 192 loss is 0.7506850957870483\n",
            "for epoch 193 loss is 0.7493491172790527\n",
            "for epoch 194 loss is 0.7480624318122864\n",
            "for epoch 195 loss is 0.7468230128288269\n",
            "for epoch 196 loss is 0.745628833770752\n",
            "for epoch 197 loss is 0.7444778084754944\n",
            "for epoch 198 loss is 0.7433680295944214\n",
            "for epoch 199 loss is 0.7422979474067688\n",
            "for epoch 200 loss is 0.7412655353546143\n",
            "for epoch 201 loss is 0.7402692437171936\n",
            "for epoch 202 loss is 0.7393075227737427\n",
            "for epoch 203 loss is 0.7383788228034973\n",
            "for epoch 204 loss is 0.7374815940856934\n",
            "for epoch 205 loss is 0.7366144061088562\n",
            "for epoch 206 loss is 0.7357761859893799\n",
            "for epoch 207 loss is 0.7349652647972107\n",
            "for epoch 208 loss is 0.7341808080673218\n",
            "for epoch 209 loss is 0.7334212064743042\n",
            "for epoch 210 loss is 0.7326858043670654\n",
            "for epoch 211 loss is 0.7319731116294861\n",
            "for epoch 212 loss is 0.7312822937965393\n",
            "for epoch 213 loss is 0.7306123971939087\n",
            "for epoch 214 loss is 0.7299624681472778\n",
            "for epoch 215 loss is 0.7293316721916199\n",
            "for epoch 216 loss is 0.7287188768386841\n",
            "for epoch 217 loss is 0.728123664855957\n",
            "for epoch 218 loss is 0.727544903755188\n",
            "for epoch 219 loss is 0.7269822359085083\n",
            "for epoch 220 loss is 0.726434588432312\n",
            "for epoch 221 loss is 0.7259016633033752\n",
            "for epoch 222 loss is 0.7253825068473816\n",
            "for epoch 223 loss is 0.7248767018318176\n",
            "for epoch 224 loss is 0.724383533000946\n",
            "for epoch 225 loss is 0.7239025831222534\n",
            "for epoch 226 loss is 0.7234333157539368\n",
            "for epoch 227 loss is 0.7229751944541931\n",
            "for epoch 228 loss is 0.7225276231765747\n",
            "for epoch 229 loss is 0.7220904231071472\n",
            "for epoch 230 loss is 0.7216629981994629\n",
            "for epoch 231 loss is 0.7212449312210083\n",
            "for epoch 232 loss is 0.7208359241485596\n",
            "for epoch 233 loss is 0.7204355001449585\n",
            "for epoch 234 loss is 0.720043420791626\n",
            "for epoch 235 loss is 0.719659149646759\n",
            "for epoch 236 loss is 0.7192826867103577\n",
            "for epoch 237 loss is 0.7189135551452637\n",
            "for epoch 238 loss is 0.7185513377189636\n",
            "for epoch 239 loss is 0.7181960344314575\n",
            "for epoch 240 loss is 0.7178471684455872\n",
            "for epoch 241 loss is 0.7175045013427734\n",
            "for epoch 242 loss is 0.7171679735183716\n",
            "for epoch 243 loss is 0.7168372869491577\n",
            "for epoch 244 loss is 0.7165120244026184\n",
            "for epoch 245 loss is 0.7161924242973328\n",
            "for epoch 246 loss is 0.7158777713775635\n",
            "for epoch 247 loss is 0.7155682444572449\n",
            "for epoch 248 loss is 0.7152634859085083\n",
            "for epoch 249 loss is 0.7149635553359985\n",
            "for epoch 250 loss is 0.7146679759025574\n",
            "for epoch 251 loss is 0.7143768668174744\n",
            "for epoch 252 loss is 0.7140899300575256\n",
            "for epoch 253 loss is 0.7138070464134216\n",
            "for epoch 254 loss is 0.7135280966758728\n",
            "for epoch 255 loss is 0.7132530212402344\n",
            "for epoch 256 loss is 0.7129815220832825\n",
            "for epoch 257 loss is 0.7127138376235962\n",
            "for epoch 258 loss is 0.7124494314193726\n",
            "for epoch 259 loss is 0.7121884226799011\n",
            "for epoch 260 loss is 0.7119306921958923\n",
            "for epoch 261 loss is 0.7116761803627014\n",
            "for epoch 262 loss is 0.7114247679710388\n",
            "for epoch 263 loss is 0.711176335811615\n",
            "for epoch 264 loss is 0.7109308838844299\n",
            "for epoch 265 loss is 0.7106882333755493\n",
            "for epoch 266 loss is 0.7104483246803284\n",
            "for epoch 267 loss is 0.7102110981941223\n",
            "for epoch 268 loss is 0.7099765539169312\n",
            "for epoch 269 loss is 0.7097444534301758\n",
            "for epoch 270 loss is 0.709514856338501\n",
            "for epoch 271 loss is 0.709287703037262\n",
            "for epoch 272 loss is 0.7090629935264587\n",
            "for epoch 273 loss is 0.7088404893875122\n",
            "for epoch 274 loss is 0.7086203098297119\n",
            "for epoch 275 loss is 0.7084023952484131\n",
            "for epoch 276 loss is 0.7081865072250366\n",
            "for epoch 277 loss is 0.7079727649688721\n",
            "for epoch 278 loss is 0.7077611684799194\n",
            "for epoch 279 loss is 0.7075515389442444\n",
            "for epoch 280 loss is 0.7073438167572021\n",
            "for epoch 281 loss is 0.707138180732727\n",
            "for epoch 282 loss is 0.70693439245224\n",
            "for epoch 283 loss is 0.706732451915741\n",
            "for epoch 284 loss is 0.70653235912323\n",
            "for epoch 285 loss is 0.7063339352607727\n",
            "for epoch 286 loss is 0.7061374187469482\n",
            "for epoch 287 loss is 0.7059425115585327\n",
            "for epoch 288 loss is 0.7057493925094604\n",
            "for epoch 289 loss is 0.7055578231811523\n",
            "for epoch 290 loss is 0.705367922782898\n",
            "for epoch 291 loss is 0.7051795721054077\n",
            "for epoch 292 loss is 0.7049928903579712\n",
            "for epoch 293 loss is 0.704807698726654\n",
            "for epoch 294 loss is 0.7046240568161011\n",
            "for epoch 295 loss is 0.7044419646263123\n",
            "for epoch 296 loss is 0.7042611837387085\n",
            "for epoch 297 loss is 0.7040819525718689\n",
            "for epoch 298 loss is 0.7039042115211487\n",
            "for epoch 299 loss is 0.7037277221679688\n",
            "for epoch 300 loss is 0.7035527229309082\n",
            "for epoch 301 loss is 0.7033790349960327\n",
            "for epoch 302 loss is 0.7032067179679871\n",
            "for epoch 303 loss is 0.7030357718467712\n",
            "for epoch 304 loss is 0.7028660774230957\n",
            "for epoch 305 loss is 0.7026975750923157\n",
            "for epoch 306 loss is 0.7025305032730103\n",
            "for epoch 307 loss is 0.7023646831512451\n",
            "for epoch 308 loss is 0.7021999359130859\n",
            "for epoch 309 loss is 0.702036440372467\n",
            "for epoch 310 loss is 0.7018741965293884\n",
            "for epoch 311 loss is 0.7017130851745605\n",
            "for epoch 312 loss is 0.701553225517273\n",
            "for epoch 313 loss is 0.7013945579528809\n",
            "for epoch 314 loss is 0.7012368440628052\n",
            "for epoch 315 loss is 0.701080322265625\n",
            "for epoch 316 loss is 0.7009249925613403\n",
            "for epoch 317 loss is 0.7007707357406616\n",
            "for epoch 318 loss is 0.7006174325942993\n",
            "for epoch 319 loss is 0.7004653811454773\n",
            "for epoch 320 loss is 0.7003143429756165\n",
            "for epoch 321 loss is 0.700164258480072\n",
            "for epoch 322 loss is 0.7000152468681335\n",
            "for epoch 323 loss is 0.699867308139801\n",
            "for epoch 324 loss is 0.6997203230857849\n",
            "for epoch 325 loss is 0.69957435131073\n",
            "for epoch 326 loss is 0.6994293332099915\n",
            "for epoch 327 loss is 0.6992852687835693\n",
            "for epoch 328 loss is 0.6991422176361084\n",
            "for epoch 329 loss is 0.6990001797676086\n",
            "for epoch 330 loss is 0.6988590359687805\n",
            "for epoch 331 loss is 0.6987187266349792\n",
            "for epoch 332 loss is 0.6985794901847839\n",
            "for epoch 333 loss is 0.6984410881996155\n",
            "for epoch 334 loss is 0.6983036398887634\n",
            "for epoch 335 loss is 0.698167085647583\n",
            "for epoch 336 loss is 0.6980313658714294\n",
            "for epoch 337 loss is 0.6978965401649475\n",
            "for epoch 338 loss is 0.697762668132782\n",
            "for epoch 339 loss is 0.6976295113563538\n",
            "for epoch 340 loss is 0.6974973082542419\n",
            "for epoch 341 loss is 0.6973658800125122\n",
            "for epoch 342 loss is 0.6972352862358093\n",
            "for epoch 343 loss is 0.6971055269241333\n",
            "for epoch 344 loss is 0.6969766020774841\n",
            "for epoch 345 loss is 0.6968485713005066\n",
            "for epoch 346 loss is 0.6967211961746216\n",
            "for epoch 347 loss is 0.6965947151184082\n",
            "for epoch 348 loss is 0.6964689493179321\n",
            "for epoch 349 loss is 0.6963440179824829\n",
            "for epoch 350 loss is 0.696219801902771\n",
            "for epoch 351 loss is 0.6960964798927307\n",
            "for epoch 352 loss is 0.6959737539291382\n",
            "for epoch 353 loss is 0.6958518624305725\n",
            "for epoch 354 loss is 0.6957307457923889\n",
            "for epoch 355 loss is 0.6956102252006531\n",
            "for epoch 356 loss is 0.6954904794692993\n",
            "for epoch 357 loss is 0.6953715682029724\n",
            "for epoch 358 loss is 0.695253312587738\n",
            "for epoch 359 loss is 0.695135772228241\n",
            "for epoch 360 loss is 0.6950189471244812\n",
            "for epoch 361 loss is 0.694902777671814\n",
            "for epoch 362 loss is 0.694787323474884\n",
            "for epoch 363 loss is 0.6946725845336914\n",
            "for epoch 364 loss is 0.6945585012435913\n",
            "for epoch 365 loss is 0.6944451332092285\n",
            "for epoch 366 loss is 0.6943323612213135\n",
            "for epoch 367 loss is 0.6942203044891357\n",
            "for epoch 368 loss is 0.694108784198761\n",
            "for epoch 369 loss is 0.6939979791641235\n",
            "for epoch 370 loss is 0.6938878893852234\n",
            "for epoch 371 loss is 0.6937784552574158\n",
            "for epoch 372 loss is 0.6936696171760559\n",
            "for epoch 373 loss is 0.6935614943504333\n",
            "for epoch 374 loss is 0.693453848361969\n",
            "for epoch 375 loss is 0.6933467984199524\n",
            "for epoch 376 loss is 0.6932404637336731\n",
            "for epoch 377 loss is 0.6931347250938416\n",
            "for epoch 378 loss is 0.693029522895813\n",
            "for epoch 379 loss is 0.6929250955581665\n",
            "for epoch 380 loss is 0.6928210854530334\n",
            "for epoch 381 loss is 0.6927177309989929\n",
            "for epoch 382 loss is 0.6926149725914001\n",
            "for epoch 383 loss is 0.6925127506256104\n",
            "for epoch 384 loss is 0.6924110651016235\n",
            "for epoch 385 loss is 0.6923100352287292\n",
            "for epoch 386 loss is 0.6922096610069275\n",
            "for epoch 387 loss is 0.6921097040176392\n",
            "for epoch 388 loss is 0.692010223865509\n",
            "for epoch 389 loss is 0.691911518573761\n",
            "for epoch 390 loss is 0.6918132901191711\n",
            "for epoch 391 loss is 0.6917155385017395\n",
            "for epoch 392 loss is 0.6916183829307556\n",
            "for epoch 393 loss is 0.6915216445922852\n",
            "for epoch 394 loss is 0.6914255619049072\n",
            "for epoch 395 loss is 0.6913300156593323\n",
            "for epoch 396 loss is 0.6912350058555603\n",
            "for epoch 397 loss is 0.6911404132843018\n",
            "for epoch 398 loss is 0.6910464763641357\n",
            "for epoch 399 loss is 0.6909528374671936\n",
            "for epoch 400 loss is 0.690859854221344\n",
            "for epoch 401 loss is 0.6907674074172974\n",
            "for epoch 402 loss is 0.6906754970550537\n",
            "for epoch 403 loss is 0.6905839443206787\n",
            "for epoch 404 loss is 0.6904929876327515\n",
            "for epoch 405 loss is 0.6904023289680481\n",
            "for epoch 406 loss is 0.690312385559082\n",
            "for epoch 407 loss is 0.6902228593826294\n",
            "for epoch 408 loss is 0.6901337504386902\n",
            "for epoch 409 loss is 0.6900452375411987\n",
            "for epoch 410 loss is 0.6899570822715759\n",
            "for epoch 411 loss is 0.6898693442344666\n",
            "for epoch 412 loss is 0.6897822022438049\n",
            "for epoch 413 loss is 0.6896955370903015\n",
            "for epoch 414 loss is 0.6896092891693115\n",
            "for epoch 415 loss is 0.6895233988761902\n",
            "for epoch 416 loss is 0.6894381046295166\n",
            "for epoch 417 loss is 0.6893531084060669\n",
            "for epoch 418 loss is 0.6892687082290649\n",
            "for epoch 419 loss is 0.6891846656799316\n",
            "for epoch 420 loss is 0.689100980758667\n",
            "for epoch 421 loss is 0.6890178322792053\n",
            "for epoch 422 loss is 0.6889350414276123\n",
            "for epoch 423 loss is 0.6888527870178223\n",
            "for epoch 424 loss is 0.6887710094451904\n",
            "for epoch 425 loss is 0.6886895298957825\n",
            "for epoch 426 loss is 0.6886085867881775\n",
            "for epoch 427 loss is 0.6885279417037964\n",
            "for epoch 428 loss is 0.6884477138519287\n",
            "for epoch 429 loss is 0.6883679628372192\n",
            "for epoch 430 loss is 0.6882885694503784\n",
            "for epoch 431 loss is 0.688209593296051\n",
            "for epoch 432 loss is 0.6881310343742371\n",
            "for epoch 433 loss is 0.688052773475647\n",
            "for epoch 434 loss is 0.6879751086235046\n",
            "for epoch 435 loss is 0.6878976225852966\n",
            "for epoch 436 loss is 0.6878206729888916\n",
            "for epoch 437 loss is 0.687744140625\n",
            "for epoch 438 loss is 0.6876679062843323\n",
            "for epoch 439 loss is 0.687592089176178\n",
            "for epoch 440 loss is 0.6875166296958923\n",
            "for epoch 441 loss is 0.6874415278434753\n",
            "for epoch 442 loss is 0.687366783618927\n",
            "for epoch 443 loss is 0.6872925162315369\n",
            "for epoch 444 loss is 0.6872186064720154\n",
            "for epoch 445 loss is 0.6871450543403625\n",
            "for epoch 446 loss is 0.6870717406272888\n",
            "for epoch 447 loss is 0.6869990229606628\n",
            "for epoch 448 loss is 0.6869264841079712\n",
            "for epoch 449 loss is 0.6868543028831482\n",
            "for epoch 450 loss is 0.6867825388908386\n",
            "for epoch 451 loss is 0.6867111325263977\n",
            "for epoch 452 loss is 0.6866400241851807\n",
            "for epoch 453 loss is 0.686569333076477\n",
            "for epoch 454 loss is 0.6864989399909973\n",
            "for epoch 455 loss is 0.6864288449287415\n",
            "for epoch 456 loss is 0.6863592863082886\n",
            "for epoch 457 loss is 0.6862898468971252\n",
            "for epoch 458 loss is 0.6862207651138306\n",
            "for epoch 459 loss is 0.6861521601676941\n",
            "for epoch 460 loss is 0.6860837936401367\n",
            "for epoch 461 loss is 0.686015784740448\n",
            "for epoch 462 loss is 0.6859481930732727\n",
            "for epoch 463 loss is 0.6858807802200317\n",
            "for epoch 464 loss is 0.6858136653900146\n",
            "for epoch 465 loss is 0.685746967792511\n",
            "for epoch 466 loss is 0.685680627822876\n",
            "for epoch 467 loss is 0.6856145262718201\n",
            "for epoch 468 loss is 0.685548722743988\n",
            "for epoch 469 loss is 0.6854833364486694\n",
            "for epoch 470 loss is 0.6854181885719299\n",
            "for epoch 471 loss is 0.6853532791137695\n",
            "for epoch 472 loss is 0.6852888464927673\n",
            "for epoch 473 loss is 0.6852245926856995\n",
            "for epoch 474 loss is 0.6851606965065002\n",
            "for epoch 475 loss is 0.6850970387458801\n",
            "for epoch 476 loss is 0.6850337386131287\n",
            "for epoch 477 loss is 0.6849707365036011\n",
            "for epoch 478 loss is 0.6849079132080078\n",
            "for epoch 479 loss is 0.6848455667495728\n",
            "for epoch 480 loss is 0.684783399105072\n",
            "for epoch 481 loss is 0.6847215890884399\n",
            "for epoch 482 loss is 0.6846600770950317\n",
            "for epoch 483 loss is 0.6845988035202026\n",
            "for epoch 484 loss is 0.6845377683639526\n",
            "for epoch 485 loss is 0.6844770908355713\n",
            "for epoch 486 loss is 0.684416651725769\n",
            "for epoch 487 loss is 0.6843565702438354\n",
            "for epoch 488 loss is 0.6842966079711914\n",
            "for epoch 489 loss is 0.6842371225357056\n",
            "for epoch 490 loss is 0.684177815914154\n",
            "for epoch 491 loss is 0.6841187477111816\n",
            "for epoch 492 loss is 0.6840599179267883\n",
            "for epoch 493 loss is 0.6840013861656189\n",
            "for epoch 494 loss is 0.6839432120323181\n",
            "for epoch 495 loss is 0.6838852763175964\n",
            "for epoch 496 loss is 0.6838275194168091\n",
            "for epoch 497 loss is 0.6837700605392456\n",
            "for epoch 498 loss is 0.6837128400802612\n",
            "for epoch 499 loss is 0.6836560368537903\n",
            "for epoch 500 loss is 0.6835993528366089\n",
            "for epoch 501 loss is 0.6835429072380066\n",
            "for epoch 502 loss is 0.6834867000579834\n",
            "for epoch 503 loss is 0.6834307909011841\n",
            "for epoch 504 loss is 0.6833751797676086\n",
            "for epoch 505 loss is 0.6833198070526123\n",
            "for epoch 506 loss is 0.6832645535469055\n",
            "for epoch 507 loss is 0.6832097768783569\n",
            "for epoch 508 loss is 0.6831549406051636\n",
            "for epoch 509 loss is 0.6831006407737732\n",
            "for epoch 510 loss is 0.6830464601516724\n",
            "for epoch 511 loss is 0.6829925179481506\n",
            "for epoch 512 loss is 0.682938814163208\n",
            "for epoch 513 loss is 0.6828853487968445\n",
            "for epoch 514 loss is 0.6828320622444153\n",
            "for epoch 515 loss is 0.68277907371521\n",
            "for epoch 516 loss is 0.682726263999939\n",
            "for epoch 517 loss is 0.6826738119125366\n",
            "for epoch 518 loss is 0.6826215386390686\n",
            "for epoch 519 loss is 0.6825694441795349\n",
            "for epoch 520 loss is 0.6825175881385803\n",
            "for epoch 521 loss is 0.6824659109115601\n",
            "for epoch 522 loss is 0.6824145913124084\n",
            "for epoch 523 loss is 0.6823633909225464\n",
            "for epoch 524 loss is 0.6823123693466187\n",
            "for epoch 525 loss is 0.6822616457939148\n",
            "for epoch 526 loss is 0.68221116065979\n",
            "for epoch 527 loss is 0.6821609735488892\n",
            "for epoch 528 loss is 0.6821108460426331\n",
            "for epoch 529 loss is 0.682060956954956\n",
            "for epoch 530 loss is 0.6820113062858582\n",
            "for epoch 531 loss is 0.6819618940353394\n",
            "for epoch 532 loss is 0.6819127202033997\n",
            "for epoch 533 loss is 0.6818636655807495\n",
            "for epoch 534 loss is 0.6818148493766785\n",
            "for epoch 535 loss is 0.6817662715911865\n",
            "for epoch 536 loss is 0.6817178726196289\n",
            "for epoch 537 loss is 0.6816696524620056\n",
            "for epoch 538 loss is 0.6816216111183167\n",
            "for epoch 539 loss is 0.6815738677978516\n",
            "for epoch 540 loss is 0.6815263628959656\n",
            "for epoch 541 loss is 0.6814789772033691\n",
            "for epoch 542 loss is 0.681431770324707\n",
            "for epoch 543 loss is 0.681384801864624\n",
            "for epoch 544 loss is 0.6813380122184753\n",
            "for epoch 545 loss is 0.6812914609909058\n",
            "for epoch 546 loss is 0.6812450885772705\n",
            "for epoch 547 loss is 0.6811988353729248\n",
            "for epoch 548 loss is 0.681152880191803\n",
            "for epoch 549 loss is 0.6811071038246155\n",
            "for epoch 550 loss is 0.6810613870620728\n",
            "for epoch 551 loss is 0.6810160279273987\n",
            "for epoch 552 loss is 0.6809707283973694\n",
            "for epoch 553 loss is 0.6809257864952087\n",
            "for epoch 554 loss is 0.6808807849884033\n",
            "for epoch 555 loss is 0.6808360815048218\n",
            "for epoch 556 loss is 0.6807916760444641\n",
            "for epoch 557 loss is 0.6807473301887512\n",
            "for epoch 558 loss is 0.6807031631469727\n",
            "for epoch 559 loss is 0.6806591749191284\n",
            "for epoch 560 loss is 0.6806154251098633\n",
            "for epoch 561 loss is 0.6805717945098877\n",
            "for epoch 562 loss is 0.6805284023284912\n",
            "for epoch 563 loss is 0.6804851293563843\n",
            "for epoch 564 loss is 0.6804421544075012\n",
            "for epoch 565 loss is 0.6803991198539734\n",
            "for epoch 566 loss is 0.6803564429283142\n",
            "for epoch 567 loss is 0.6803138256072998\n",
            "for epoch 568 loss is 0.680271565914154\n",
            "for epoch 569 loss is 0.6802293062210083\n",
            "for epoch 570 loss is 0.6801873445510864\n",
            "for epoch 571 loss is 0.6801453828811646\n",
            "for epoch 572 loss is 0.6801037192344666\n",
            "for epoch 573 loss is 0.6800621151924133\n",
            "for epoch 574 loss is 0.6800206899642944\n",
            "for epoch 575 loss is 0.6799794435501099\n",
            "for epoch 576 loss is 0.6799384951591492\n",
            "for epoch 577 loss is 0.6798974871635437\n",
            "for epoch 578 loss is 0.6798568367958069\n",
            "for epoch 579 loss is 0.6798163056373596\n",
            "for epoch 580 loss is 0.6797758936882019\n",
            "for epoch 581 loss is 0.6797356009483337\n",
            "for epoch 582 loss is 0.6796956062316895\n",
            "for epoch 583 loss is 0.6796556115150452\n",
            "for epoch 584 loss is 0.67961585521698\n",
            "for epoch 585 loss is 0.6795762181282043\n",
            "for epoch 586 loss is 0.679536759853363\n",
            "for epoch 587 loss is 0.679497480392456\n",
            "for epoch 588 loss is 0.6794583201408386\n",
            "for epoch 589 loss is 0.679419219493866\n",
            "for epoch 590 loss is 0.6793805360794067\n",
            "for epoch 591 loss is 0.679341733455658\n",
            "for epoch 592 loss is 0.6793032288551331\n",
            "for epoch 593 loss is 0.6792647838592529\n",
            "for epoch 594 loss is 0.6792265176773071\n",
            "for epoch 595 loss is 0.6791884303092957\n",
            "for epoch 596 loss is 0.679150402545929\n",
            "for epoch 597 loss is 0.6791126728057861\n",
            "for epoch 598 loss is 0.6790750026702881\n",
            "for epoch 599 loss is 0.6790374517440796\n",
            "for epoch 600 loss is 0.6790000200271606\n",
            "for epoch 601 loss is 0.678962767124176\n",
            "for epoch 602 loss is 0.6789256930351257\n",
            "for epoch 603 loss is 0.678888738155365\n",
            "for epoch 604 loss is 0.6788519024848938\n",
            "for epoch 605 loss is 0.6788151860237122\n",
            "for epoch 606 loss is 0.6787785887718201\n",
            "for epoch 607 loss is 0.6787422299385071\n",
            "for epoch 608 loss is 0.6787059903144836\n",
            "for epoch 609 loss is 0.6786698698997498\n",
            "for epoch 610 loss is 0.6786337494850159\n",
            "for epoch 611 loss is 0.6785979866981506\n",
            "for epoch 612 loss is 0.6785622239112854\n",
            "for epoch 613 loss is 0.6785265803337097\n",
            "for epoch 614 loss is 0.6784911751747131\n",
            "for epoch 615 loss is 0.6784558296203613\n",
            "for epoch 616 loss is 0.6784206032752991\n",
            "for epoch 617 loss is 0.6783855557441711\n",
            "for epoch 618 loss is 0.678350567817688\n",
            "for epoch 619 loss is 0.6783158183097839\n",
            "for epoch 620 loss is 0.6782810688018799\n",
            "for epoch 621 loss is 0.6782464981079102\n",
            "for epoch 622 loss is 0.6782121062278748\n",
            "for epoch 623 loss is 0.6781777739524841\n",
            "for epoch 624 loss is 0.6781436204910278\n",
            "for epoch 625 loss is 0.6781095266342163\n",
            "for epoch 626 loss is 0.6780756115913391\n",
            "for epoch 627 loss is 0.6780418157577515\n",
            "for epoch 628 loss is 0.6780080795288086\n",
            "for epoch 629 loss is 0.6779745817184448\n",
            "for epoch 630 loss is 0.677941083908081\n",
            "for epoch 631 loss is 0.6779077649116516\n",
            "for epoch 632 loss is 0.6778745651245117\n",
            "for epoch 633 loss is 0.6778415441513062\n",
            "for epoch 634 loss is 0.6778085231781006\n",
            "for epoch 635 loss is 0.6777756810188293\n",
            "for epoch 636 loss is 0.6777428984642029\n",
            "for epoch 637 loss is 0.6777102947235107\n",
            "for epoch 638 loss is 0.6776778101921082\n",
            "for epoch 639 loss is 0.6776454448699951\n",
            "for epoch 640 loss is 0.6776131987571716\n",
            "for epoch 641 loss is 0.6775810718536377\n",
            "for epoch 642 loss is 0.6775490045547485\n",
            "for epoch 643 loss is 0.6775170564651489\n",
            "for epoch 644 loss is 0.6774852275848389\n",
            "for epoch 645 loss is 0.6774535179138184\n",
            "for epoch 646 loss is 0.6774218678474426\n",
            "for epoch 647 loss is 0.6773905754089355\n",
            "for epoch 648 loss is 0.6773591041564941\n",
            "for epoch 649 loss is 0.6773278713226318\n",
            "for epoch 650 loss is 0.6772966980934143\n",
            "for epoch 651 loss is 0.6772656440734863\n",
            "for epoch 652 loss is 0.6772347092628479\n",
            "for epoch 653 loss is 0.6772038340568542\n",
            "for epoch 654 loss is 0.6771731972694397\n",
            "for epoch 655 loss is 0.6771426200866699\n",
            "for epoch 656 loss is 0.6771119832992554\n",
            "for epoch 657 loss is 0.6770816445350647\n",
            "for epoch 658 loss is 0.6770513653755188\n",
            "for epoch 659 loss is 0.6770212054252625\n",
            "for epoch 660 loss is 0.6769911050796509\n",
            "for epoch 661 loss is 0.6769610643386841\n",
            "for epoch 662 loss is 0.6769312024116516\n",
            "for epoch 663 loss is 0.6769015192985535\n",
            "for epoch 664 loss is 0.6768717765808105\n",
            "for epoch 665 loss is 0.6768421530723572\n",
            "for epoch 666 loss is 0.6768127083778381\n",
            "for epoch 667 loss is 0.6767833232879639\n",
            "for epoch 668 loss is 0.6767539978027344\n",
            "for epoch 669 loss is 0.676724910736084\n",
            "for epoch 670 loss is 0.6766958236694336\n",
            "for epoch 671 loss is 0.676666796207428\n",
            "for epoch 672 loss is 0.6766379475593567\n",
            "for epoch 673 loss is 0.6766090989112854\n",
            "for epoch 674 loss is 0.6765804290771484\n",
            "for epoch 675 loss is 0.6765518188476562\n",
            "for epoch 676 loss is 0.6765233874320984\n",
            "for epoch 677 loss is 0.6764950156211853\n",
            "for epoch 678 loss is 0.6764665842056274\n",
            "for epoch 679 loss is 0.6764384508132935\n",
            "for epoch 680 loss is 0.6764103174209595\n",
            "for epoch 681 loss is 0.676382303237915\n",
            "for epoch 682 loss is 0.6763542890548706\n",
            "for epoch 683 loss is 0.6763264536857605\n",
            "for epoch 684 loss is 0.6762986779212952\n",
            "for epoch 685 loss is 0.6762709617614746\n",
            "for epoch 686 loss is 0.6762434840202332\n",
            "for epoch 687 loss is 0.6762160658836365\n",
            "for epoch 688 loss is 0.676188588142395\n",
            "for epoch 689 loss is 0.6761614084243774\n",
            "for epoch 690 loss is 0.6761341691017151\n",
            "for epoch 691 loss is 0.6761069893836975\n",
            "for epoch 692 loss is 0.6760799288749695\n",
            "for epoch 693 loss is 0.676052987575531\n",
            "for epoch 694 loss is 0.6760261654853821\n",
            "for epoch 695 loss is 0.6759992837905884\n",
            "for epoch 696 loss is 0.6759726405143738\n",
            "for epoch 697 loss is 0.6759459972381592\n",
            "for epoch 698 loss is 0.6759194731712341\n",
            "for epoch 699 loss is 0.6758930683135986\n",
            "for epoch 700 loss is 0.6758667230606079\n",
            "for epoch 701 loss is 0.6758404970169067\n",
            "for epoch 702 loss is 0.6758142709732056\n",
            "for epoch 703 loss is 0.6757882237434387\n",
            "for epoch 704 loss is 0.6757621169090271\n",
            "for epoch 705 loss is 0.6757363080978394\n",
            "for epoch 706 loss is 0.6757104396820068\n",
            "for epoch 707 loss is 0.6756846308708191\n",
            "for epoch 708 loss is 0.6756589412689209\n",
            "for epoch 709 loss is 0.6756333708763123\n",
            "for epoch 710 loss is 0.6756078600883484\n",
            "for epoch 711 loss is 0.6755824089050293\n",
            "for epoch 712 loss is 0.675557017326355\n",
            "for epoch 713 loss is 0.6755316853523254\n",
            "for epoch 714 loss is 0.6755065321922302\n",
            "for epoch 715 loss is 0.675481379032135\n",
            "for epoch 716 loss is 0.6754564046859741\n",
            "for epoch 717 loss is 0.6754313111305237\n",
            "for epoch 718 loss is 0.6754065155982971\n",
            "for epoch 719 loss is 0.6753816604614258\n",
            "for epoch 720 loss is 0.675356924533844\n",
            "for epoch 721 loss is 0.675332248210907\n",
            "for epoch 722 loss is 0.6753076910972595\n",
            "for epoch 723 loss is 0.6752831935882568\n",
            "for epoch 724 loss is 0.6752586960792542\n",
            "for epoch 725 loss is 0.6752344369888306\n",
            "for epoch 726 loss is 0.6752101182937622\n",
            "for epoch 727 loss is 0.6751857995986938\n",
            "for epoch 728 loss is 0.6751616597175598\n",
            "for epoch 729 loss is 0.6751376390457153\n",
            "for epoch 730 loss is 0.6751136779785156\n",
            "for epoch 731 loss is 0.6750897169113159\n",
            "for epoch 732 loss is 0.6750659346580505\n",
            "for epoch 733 loss is 0.6750422120094299\n",
            "for epoch 734 loss is 0.6750184297561646\n",
            "for epoch 735 loss is 0.6749947667121887\n",
            "for epoch 736 loss is 0.6749712228775024\n",
            "for epoch 737 loss is 0.6749477982521057\n",
            "for epoch 738 loss is 0.6749243140220642\n",
            "for epoch 739 loss is 0.6749009490013123\n",
            "for epoch 740 loss is 0.6748777031898499\n",
            "for epoch 741 loss is 0.6748544573783875\n",
            "for epoch 742 loss is 0.6748313903808594\n",
            "for epoch 743 loss is 0.6748083233833313\n",
            "for epoch 744 loss is 0.6747852563858032\n",
            "for epoch 745 loss is 0.6747623085975647\n",
            "for epoch 746 loss is 0.6747394800186157\n",
            "for epoch 747 loss is 0.6747166514396667\n",
            "for epoch 748 loss is 0.6746939420700073\n",
            "for epoch 749 loss is 0.6746712327003479\n",
            "for epoch 750 loss is 0.674648642539978\n",
            "for epoch 751 loss is 0.6746261715888977\n",
            "for epoch 752 loss is 0.6746037602424622\n",
            "for epoch 753 loss is 0.6745811700820923\n",
            "for epoch 754 loss is 0.6745589375495911\n",
            "for epoch 755 loss is 0.6745366454124451\n",
            "for epoch 756 loss is 0.6745144128799438\n",
            "for epoch 757 loss is 0.6744922995567322\n",
            "for epoch 758 loss is 0.6744702458381653\n",
            "for epoch 759 loss is 0.6744483113288879\n",
            "for epoch 760 loss is 0.674426257610321\n",
            "for epoch 761 loss is 0.6744043827056885\n",
            "for epoch 762 loss is 0.6743825674057007\n",
            "for epoch 763 loss is 0.6743608117103577\n",
            "for epoch 764 loss is 0.6743390560150146\n",
            "for epoch 765 loss is 0.6743174195289612\n",
            "for epoch 766 loss is 0.6742958426475525\n",
            "for epoch 767 loss is 0.6742743849754333\n",
            "for epoch 768 loss is 0.674252986907959\n",
            "for epoch 769 loss is 0.6742315292358398\n",
            "for epoch 770 loss is 0.6742101907730103\n",
            "for epoch 771 loss is 0.6741889715194702\n",
            "for epoch 772 loss is 0.6741676926612854\n",
            "for epoch 773 loss is 0.6741465330123901\n",
            "for epoch 774 loss is 0.6741254925727844\n",
            "for epoch 775 loss is 0.6741044521331787\n",
            "for epoch 776 loss is 0.6740834712982178\n",
            "for epoch 777 loss is 0.6740625500679016\n",
            "for epoch 778 loss is 0.6740416884422302\n",
            "for epoch 779 loss is 0.6740208864212036\n",
            "for epoch 780 loss is 0.6740002036094666\n",
            "for epoch 781 loss is 0.6739795207977295\n",
            "for epoch 782 loss is 0.6739588975906372\n",
            "for epoch 783 loss is 0.6739383935928345\n",
            "for epoch 784 loss is 0.673917829990387\n",
            "for epoch 785 loss is 0.673897385597229\n",
            "for epoch 786 loss is 0.6738770008087158\n",
            "for epoch 787 loss is 0.6738566160202026\n",
            "for epoch 788 loss is 0.673836350440979\n",
            "for epoch 789 loss is 0.6738161444664001\n",
            "for epoch 790 loss is 0.6737959384918213\n",
            "for epoch 791 loss is 0.6737757921218872\n",
            "for epoch 792 loss is 0.6737558245658875\n",
            "for epoch 793 loss is 0.6737357974052429\n",
            "for epoch 794 loss is 0.6737158894538879\n",
            "for epoch 795 loss is 0.673695981502533\n",
            "for epoch 796 loss is 0.6736761331558228\n",
            "for epoch 797 loss is 0.6736563444137573\n",
            "for epoch 798 loss is 0.6736365556716919\n",
            "for epoch 799 loss is 0.673616886138916\n",
            "for epoch 800 loss is 0.6735972166061401\n",
            "for epoch 801 loss is 0.673577606678009\n",
            "for epoch 802 loss is 0.6735581159591675\n",
            "for epoch 803 loss is 0.6735386848449707\n",
            "for epoch 804 loss is 0.6735192537307739\n",
            "for epoch 805 loss is 0.6734998822212219\n",
            "for epoch 806 loss is 0.6734805703163147\n",
            "for epoch 807 loss is 0.6734613180160522\n",
            "for epoch 808 loss is 0.6734420657157898\n",
            "for epoch 809 loss is 0.6734230518341064\n",
            "for epoch 810 loss is 0.6734038591384888\n",
            "for epoch 811 loss is 0.6733847856521606\n",
            "for epoch 812 loss is 0.6733658313751221\n",
            "for epoch 813 loss is 0.6733468174934387\n",
            "for epoch 814 loss is 0.6733279228210449\n",
            "for epoch 815 loss is 0.6733090877532959\n",
            "for epoch 816 loss is 0.6732901930809021\n",
            "for epoch 817 loss is 0.6732714772224426\n",
            "for epoch 818 loss is 0.6732527613639832\n",
            "for epoch 819 loss is 0.6732340455055237\n",
            "for epoch 820 loss is 0.6732155680656433\n",
            "for epoch 821 loss is 0.6731969118118286\n",
            "for epoch 822 loss is 0.6731784343719482\n",
            "for epoch 823 loss is 0.6731599569320679\n",
            "for epoch 824 loss is 0.6731415390968323\n",
            "for epoch 825 loss is 0.6731232404708862\n",
            "for epoch 826 loss is 0.6731048226356506\n",
            "for epoch 827 loss is 0.6730866432189941\n",
            "for epoch 828 loss is 0.6730683445930481\n",
            "for epoch 829 loss is 0.6730502247810364\n",
            "for epoch 830 loss is 0.6730321049690247\n",
            "for epoch 831 loss is 0.6730139851570129\n",
            "for epoch 832 loss is 0.6729958653450012\n",
            "for epoch 833 loss is 0.6729779243469238\n",
            "for epoch 834 loss is 0.6729599237442017\n",
            "for epoch 835 loss is 0.6729421019554138\n",
            "for epoch 836 loss is 0.6729242205619812\n",
            "for epoch 837 loss is 0.6729063987731934\n",
            "for epoch 838 loss is 0.6728886961936951\n",
            "for epoch 839 loss is 0.6728708744049072\n",
            "for epoch 840 loss is 0.6728532314300537\n",
            "for epoch 841 loss is 0.672835648059845\n",
            "for epoch 842 loss is 0.6728180646896362\n",
            "for epoch 843 loss is 0.6728004813194275\n",
            "for epoch 844 loss is 0.6727830171585083\n",
            "for epoch 845 loss is 0.6727654933929443\n",
            "for epoch 846 loss is 0.6727480888366699\n",
            "for epoch 847 loss is 0.6727308034896851\n",
            "for epoch 848 loss is 0.6727133393287659\n",
            "for epoch 849 loss is 0.6726961731910706\n",
            "for epoch 850 loss is 0.6726787686347961\n",
            "for epoch 851 loss is 0.6726616621017456\n",
            "for epoch 852 loss is 0.6726445555686951\n",
            "for epoch 853 loss is 0.6726274490356445\n",
            "for epoch 854 loss is 0.672610342502594\n",
            "for epoch 855 loss is 0.672593355178833\n",
            "for epoch 856 loss is 0.672576367855072\n",
            "for epoch 857 loss is 0.672559380531311\n",
            "for epoch 858 loss is 0.6725425124168396\n",
            "for epoch 859 loss is 0.6725256443023682\n",
            "for epoch 860 loss is 0.6725088357925415\n",
            "for epoch 861 loss is 0.6724920868873596\n",
            "for epoch 862 loss is 0.6724753379821777\n",
            "for epoch 863 loss is 0.6724586486816406\n",
            "for epoch 864 loss is 0.6724419593811035\n",
            "for epoch 865 loss is 0.6724254488945007\n",
            "for epoch 866 loss is 0.6724088191986084\n",
            "for epoch 867 loss is 0.6723922491073608\n",
            "for epoch 868 loss is 0.6723757982254028\n",
            "for epoch 869 loss is 0.6723592281341553\n",
            "for epoch 870 loss is 0.672342836856842\n",
            "for epoch 871 loss is 0.6723265051841736\n",
            "for epoch 872 loss is 0.6723101735115051\n",
            "for epoch 873 loss is 0.6722939014434814\n",
            "for epoch 874 loss is 0.672277569770813\n",
            "for epoch 875 loss is 0.6722614765167236\n",
            "for epoch 876 loss is 0.6722452044487\n",
            "for epoch 877 loss is 0.6722290515899658\n",
            "for epoch 878 loss is 0.6722129583358765\n",
            "for epoch 879 loss is 0.6721969246864319\n",
            "for epoch 880 loss is 0.6721808910369873\n",
            "for epoch 881 loss is 0.6721649765968323\n",
            "for epoch 882 loss is 0.6721489429473877\n",
            "for epoch 883 loss is 0.6721330285072327\n",
            "for epoch 884 loss is 0.6721171736717224\n",
            "for epoch 885 loss is 0.6721013188362122\n",
            "for epoch 886 loss is 0.6720855236053467\n",
            "for epoch 887 loss is 0.6720697283744812\n",
            "for epoch 888 loss is 0.6720540523529053\n",
            "for epoch 889 loss is 0.6720383167266846\n",
            "for epoch 890 loss is 0.6720227003097534\n",
            "for epoch 891 loss is 0.6720070838928223\n",
            "for epoch 892 loss is 0.6719915270805359\n",
            "for epoch 893 loss is 0.6719759702682495\n",
            "for epoch 894 loss is 0.6719604134559631\n",
            "for epoch 895 loss is 0.6719449758529663\n",
            "for epoch 896 loss is 0.6719295382499695\n",
            "for epoch 897 loss is 0.6719141602516174\n",
            "for epoch 898 loss is 0.6718987822532654\n",
            "for epoch 899 loss is 0.6718834638595581\n",
            "for epoch 900 loss is 0.6718682050704956\n",
            "for epoch 901 loss is 0.6718529462814331\n",
            "for epoch 902 loss is 0.6718376874923706\n",
            "for epoch 903 loss is 0.6718225479125977\n",
            "for epoch 904 loss is 0.6718073487281799\n",
            "for epoch 905 loss is 0.671792209148407\n",
            "for epoch 906 loss is 0.6717771887779236\n",
            "for epoch 907 loss is 0.6717621088027954\n",
            "for epoch 908 loss is 0.671747088432312\n",
            "for epoch 909 loss is 0.6717321276664734\n",
            "for epoch 910 loss is 0.6717171669006348\n",
            "for epoch 911 loss is 0.6717023253440857\n",
            "for epoch 912 loss is 0.6716873645782471\n",
            "for epoch 913 loss is 0.6716725826263428\n",
            "for epoch 914 loss is 0.6716576814651489\n",
            "for epoch 915 loss is 0.6716430187225342\n",
            "for epoch 916 loss is 0.6716282963752747\n",
            "for epoch 917 loss is 0.6716133952140808\n",
            "for epoch 918 loss is 0.6715988516807556\n",
            "for epoch 919 loss is 0.6715841889381409\n",
            "for epoch 920 loss is 0.6715695858001709\n",
            "for epoch 921 loss is 0.6715549826622009\n",
            "for epoch 922 loss is 0.6715404391288757\n",
            "for epoch 923 loss is 0.6715259552001953\n",
            "for epoch 924 loss is 0.6715115308761597\n",
            "for epoch 925 loss is 0.6714969277381897\n",
            "for epoch 926 loss is 0.6714826226234436\n",
            "for epoch 927 loss is 0.671468198299408\n",
            "for epoch 928 loss is 0.6714537739753723\n",
            "for epoch 929 loss is 0.671439528465271\n",
            "for epoch 930 loss is 0.6714252233505249\n",
            "for epoch 931 loss is 0.6714109182357788\n",
            "for epoch 932 loss is 0.6713967323303223\n",
            "for epoch 933 loss is 0.6713826060295105\n",
            "for epoch 934 loss is 0.6713683605194092\n",
            "for epoch 935 loss is 0.6713542342185974\n",
            "for epoch 936 loss is 0.6713401675224304\n",
            "for epoch 937 loss is 0.6713261008262634\n",
            "for epoch 938 loss is 0.6713120937347412\n",
            "for epoch 939 loss is 0.6712980270385742\n",
            "for epoch 940 loss is 0.671284019947052\n",
            "for epoch 941 loss is 0.6712700724601746\n",
            "for epoch 942 loss is 0.6712561845779419\n",
            "for epoch 943 loss is 0.6712422966957092\n",
            "for epoch 944 loss is 0.6712284088134766\n",
            "for epoch 945 loss is 0.6712145805358887\n",
            "for epoch 946 loss is 0.6712008118629456\n",
            "for epoch 947 loss is 0.6711870431900024\n",
            "for epoch 948 loss is 0.6711733341217041\n",
            "for epoch 949 loss is 0.6711595058441162\n",
            "for epoch 950 loss is 0.6711459159851074\n",
            "for epoch 951 loss is 0.6711322665214539\n",
            "for epoch 952 loss is 0.6711186170578003\n",
            "for epoch 953 loss is 0.6711050271987915\n",
            "for epoch 954 loss is 0.6710914373397827\n",
            "for epoch 955 loss is 0.6710779070854187\n",
            "for epoch 956 loss is 0.6710644364356995\n",
            "for epoch 957 loss is 0.6710509657859802\n",
            "for epoch 958 loss is 0.6710374355316162\n",
            "for epoch 959 loss is 0.6710240244865417\n",
            "for epoch 960 loss is 0.6710106730461121\n",
            "for epoch 961 loss is 0.6709973216056824\n",
            "for epoch 962 loss is 0.6709840297698975\n",
            "for epoch 963 loss is 0.6709706783294678\n",
            "for epoch 964 loss is 0.6709573268890381\n",
            "for epoch 965 loss is 0.6709441542625427\n",
            "for epoch 966 loss is 0.670930802822113\n",
            "for epoch 967 loss is 0.6709176898002625\n",
            "for epoch 968 loss is 0.6709044575691223\n",
            "for epoch 969 loss is 0.6708914041519165\n",
            "for epoch 970 loss is 0.6708782911300659\n",
            "for epoch 971 loss is 0.6708652377128601\n",
            "for epoch 972 loss is 0.6708521842956543\n",
            "for epoch 973 loss is 0.6708391308784485\n",
            "for epoch 974 loss is 0.6708261370658875\n",
            "for epoch 975 loss is 0.6708130836486816\n",
            "for epoch 976 loss is 0.6708001494407654\n",
            "for epoch 977 loss is 0.6707872748374939\n",
            "for epoch 978 loss is 0.6707743406295776\n",
            "for epoch 979 loss is 0.6707614660263062\n",
            "for epoch 980 loss is 0.6707486510276794\n",
            "for epoch 981 loss is 0.670735776424408\n",
            "for epoch 982 loss is 0.6707229614257812\n",
            "for epoch 983 loss is 0.6707102060317993\n",
            "for epoch 984 loss is 0.6706974506378174\n",
            "for epoch 985 loss is 0.6706847548484802\n",
            "for epoch 986 loss is 0.6706721782684326\n",
            "for epoch 987 loss is 0.6706594228744507\n",
            "for epoch 988 loss is 0.6706469058990479\n",
            "for epoch 989 loss is 0.6706342101097107\n",
            "for epoch 990 loss is 0.6706215739250183\n",
            "for epoch 991 loss is 0.6706090569496155\n",
            "for epoch 992 loss is 0.6705964803695679\n",
            "for epoch 993 loss is 0.6705840229988098\n",
            "for epoch 994 loss is 0.6705715656280518\n",
            "for epoch 995 loss is 0.6705591082572937\n",
            "for epoch 996 loss is 0.6705466508865356\n",
            "for epoch 997 loss is 0.6705341935157776\n",
            "for epoch 998 loss is 0.6705218553543091\n",
            "for epoch 999 loss is 0.6705094575881958\n",
            "for epoch 1000 loss is 0.6704971194267273\n",
            "for epoch 1001 loss is 0.6704848408699036\n",
            "for epoch 1002 loss is 0.6704725623130798\n",
            "for epoch 1003 loss is 0.6704603433609009\n",
            "for epoch 1004 loss is 0.6704480051994324\n",
            "for epoch 1005 loss is 0.6704358458518982\n",
            "for epoch 1006 loss is 0.670423686504364\n",
            "for epoch 1007 loss is 0.6704114675521851\n",
            "for epoch 1008 loss is 0.6703994274139404\n",
            "for epoch 1009 loss is 0.6703872680664062\n",
            "for epoch 1010 loss is 0.6703751683235168\n",
            "for epoch 1011 loss is 0.670363187789917\n",
            "for epoch 1012 loss is 0.6703510880470276\n",
            "for epoch 1013 loss is 0.670339047908783\n",
            "for epoch 1014 loss is 0.6703270077705383\n",
            "for epoch 1015 loss is 0.6703152060508728\n",
            "for epoch 1016 loss is 0.6703031063079834\n",
            "for epoch 1017 loss is 0.6702912449836731\n",
            "for epoch 1018 loss is 0.670279324054718\n",
            "for epoch 1019 loss is 0.6702674031257629\n",
            "for epoch 1020 loss is 0.6702556014060974\n",
            "for epoch 1021 loss is 0.6702436804771423\n",
            "for epoch 1022 loss is 0.6702319979667664\n",
            "for epoch 1023 loss is 0.670220136642456\n",
            "for epoch 1024 loss is 0.6702083945274353\n",
            "for epoch 1025 loss is 0.6701967120170593\n",
            "for epoch 1026 loss is 0.6701849102973938\n",
            "for epoch 1027 loss is 0.6701732873916626\n",
            "for epoch 1028 loss is 0.6701616644859314\n",
            "for epoch 1029 loss is 0.6701499819755554\n",
            "for epoch 1030 loss is 0.6701382398605347\n",
            "for epoch 1031 loss is 0.6701266169548035\n",
            "for epoch 1032 loss is 0.6701151728630066\n",
            "for epoch 1033 loss is 0.6701036095619202\n",
            "for epoch 1034 loss is 0.6700921058654785\n",
            "for epoch 1035 loss is 0.6700805425643921\n",
            "for epoch 1036 loss is 0.67006915807724\n",
            "for epoch 1037 loss is 0.6700575947761536\n",
            "for epoch 1038 loss is 0.6700460910797119\n",
            "for epoch 1039 loss is 0.670034646987915\n",
            "for epoch 1040 loss is 0.6700232625007629\n",
            "for epoch 1041 loss is 0.6700119376182556\n",
            "for epoch 1042 loss is 0.6700005531311035\n",
            "for epoch 1043 loss is 0.6699892282485962\n",
            "for epoch 1044 loss is 0.6699779033660889\n",
            "for epoch 1045 loss is 0.6699665784835815\n",
            "for epoch 1046 loss is 0.669955313205719\n",
            "for epoch 1047 loss is 0.6699440479278564\n",
            "for epoch 1048 loss is 0.6699328422546387\n",
            "for epoch 1049 loss is 0.6699216365814209\n",
            "for epoch 1050 loss is 0.6699104309082031\n",
            "for epoch 1051 loss is 0.6698993444442749\n",
            "for epoch 1052 loss is 0.6698881387710571\n",
            "for epoch 1053 loss is 0.6698769927024841\n",
            "for epoch 1054 loss is 0.6698659062385559\n",
            "for epoch 1055 loss is 0.6698547601699829\n",
            "for epoch 1056 loss is 0.6698437929153442\n",
            "for epoch 1057 loss is 0.6698326468467712\n",
            "for epoch 1058 loss is 0.6698217391967773\n",
            "for epoch 1059 loss is 0.6698106527328491\n",
            "for epoch 1060 loss is 0.6697996854782104\n",
            "for epoch 1061 loss is 0.6697887778282166\n",
            "for epoch 1062 loss is 0.6697778105735779\n",
            "for epoch 1063 loss is 0.6697669625282288\n",
            "for epoch 1064 loss is 0.6697560548782349\n",
            "for epoch 1065 loss is 0.669745147228241\n",
            "for epoch 1066 loss is 0.6697342395782471\n",
            "for epoch 1067 loss is 0.669723391532898\n",
            "for epoch 1068 loss is 0.6697126030921936\n",
            "for epoch 1069 loss is 0.6697018146514893\n",
            "for epoch 1070 loss is 0.6696910262107849\n",
            "for epoch 1071 loss is 0.6696802973747253\n",
            "for epoch 1072 loss is 0.6696695685386658\n",
            "for epoch 1073 loss is 0.6696587204933167\n",
            "for epoch 1074 loss is 0.6696481108665466\n",
            "for epoch 1075 loss is 0.6696373224258423\n",
            "for epoch 1076 loss is 0.669626772403717\n",
            "for epoch 1077 loss is 0.6696160435676575\n",
            "for epoch 1078 loss is 0.6696054935455322\n",
            "for epoch 1079 loss is 0.6695948839187622\n",
            "for epoch 1080 loss is 0.6695843935012817\n",
            "for epoch 1081 loss is 0.6695737838745117\n",
            "for epoch 1082 loss is 0.6695631742477417\n",
            "for epoch 1083 loss is 0.669552743434906\n",
            "for epoch 1084 loss is 0.6695421934127808\n",
            "for epoch 1085 loss is 0.6695315837860107\n",
            "for epoch 1086 loss is 0.6695212721824646\n",
            "for epoch 1087 loss is 0.6695107817649841\n",
            "for epoch 1088 loss is 0.6695003509521484\n",
            "for epoch 1089 loss is 0.6694899201393127\n",
            "for epoch 1090 loss is 0.6694795489311218\n",
            "for epoch 1091 loss is 0.6694691181182861\n",
            "for epoch 1092 loss is 0.6694587469100952\n",
            "for epoch 1093 loss is 0.6694484353065491\n",
            "for epoch 1094 loss is 0.6694381833076477\n",
            "for epoch 1095 loss is 0.6694279313087463\n",
            "for epoch 1096 loss is 0.6694175601005554\n",
            "for epoch 1097 loss is 0.669407308101654\n",
            "for epoch 1098 loss is 0.6693971157073975\n",
            "for epoch 1099 loss is 0.6693868637084961\n",
            "for epoch 1100 loss is 0.6693766117095947\n",
            "for epoch 1101 loss is 0.6693664789199829\n",
            "for epoch 1102 loss is 0.6693562865257263\n",
            "for epoch 1103 loss is 0.6693460941314697\n",
            "for epoch 1104 loss is 0.6693359017372131\n",
            "for epoch 1105 loss is 0.6693257689476013\n",
            "for epoch 1106 loss is 0.669315755367279\n",
            "for epoch 1107 loss is 0.6693056225776672\n",
            "for epoch 1108 loss is 0.6692956686019897\n",
            "for epoch 1109 loss is 0.6692855358123779\n",
            "for epoch 1110 loss is 0.6692755222320557\n",
            "for epoch 1111 loss is 0.6692655682563782\n",
            "for epoch 1112 loss is 0.6692554950714111\n",
            "for epoch 1113 loss is 0.6692456603050232\n",
            "for epoch 1114 loss is 0.6692355871200562\n",
            "for epoch 1115 loss is 0.6692256331443787\n",
            "for epoch 1116 loss is 0.669215738773346\n",
            "for epoch 1117 loss is 0.6692058444023132\n",
            "for epoch 1118 loss is 0.6691958904266357\n",
            "for epoch 1119 loss is 0.6691861152648926\n",
            "for epoch 1120 loss is 0.6691762208938599\n",
            "for epoch 1121 loss is 0.6691663861274719\n",
            "for epoch 1122 loss is 0.669156551361084\n",
            "for epoch 1123 loss is 0.6691468358039856\n",
            "for epoch 1124 loss is 0.6691370010375977\n",
            "for epoch 1125 loss is 0.6691272258758545\n",
            "for epoch 1126 loss is 0.6691173911094666\n",
            "for epoch 1127 loss is 0.6691077351570129\n",
            "for epoch 1128 loss is 0.6690980195999146\n",
            "for epoch 1129 loss is 0.6690883636474609\n",
            "for epoch 1130 loss is 0.6690787076950073\n",
            "for epoch 1131 loss is 0.6690690517425537\n",
            "for epoch 1132 loss is 0.6690593957901001\n",
            "for epoch 1133 loss is 0.6690497994422913\n",
            "for epoch 1134 loss is 0.6690401434898376\n",
            "for epoch 1135 loss is 0.669030487537384\n",
            "for epoch 1136 loss is 0.6690208911895752\n",
            "for epoch 1137 loss is 0.6690113544464111\n",
            "for epoch 1138 loss is 0.6690017580986023\n",
            "for epoch 1139 loss is 0.668992280960083\n",
            "for epoch 1140 loss is 0.6689826846122742\n",
            "for epoch 1141 loss is 0.6689732670783997\n",
            "for epoch 1142 loss is 0.6689637303352356\n",
            "for epoch 1143 loss is 0.6689542531967163\n",
            "for epoch 1144 loss is 0.6689448952674866\n",
            "for epoch 1145 loss is 0.6689354181289673\n",
            "for epoch 1146 loss is 0.668925940990448\n",
            "for epoch 1147 loss is 0.6689165830612183\n",
            "for epoch 1148 loss is 0.6689072251319885\n",
            "for epoch 1149 loss is 0.6688978672027588\n",
            "for epoch 1150 loss is 0.6688883900642395\n",
            "for epoch 1151 loss is 0.6688791513442993\n",
            "for epoch 1152 loss is 0.6688697934150696\n",
            "for epoch 1153 loss is 0.6688605546951294\n",
            "for epoch 1154 loss is 0.6688511967658997\n",
            "for epoch 1155 loss is 0.6688418984413147\n",
            "for epoch 1156 loss is 0.6688326597213745\n",
            "for epoch 1157 loss is 0.6688233613967896\n",
            "for epoch 1158 loss is 0.6688142418861389\n",
            "for epoch 1159 loss is 0.668804943561554\n",
            "for epoch 1160 loss is 0.6687957644462585\n",
            "for epoch 1161 loss is 0.6687865853309631\n",
            "for epoch 1162 loss is 0.6687774658203125\n",
            "for epoch 1163 loss is 0.6687682867050171\n",
            "for epoch 1164 loss is 0.6687592267990112\n",
            "for epoch 1165 loss is 0.668749988079071\n",
            "for epoch 1166 loss is 0.6687409281730652\n",
            "for epoch 1167 loss is 0.6687318086624146\n",
            "for epoch 1168 loss is 0.6687226891517639\n",
            "for epoch 1169 loss is 0.6687136888504028\n",
            "for epoch 1170 loss is 0.668704628944397\n",
            "for epoch 1171 loss is 0.6686955690383911\n",
            "for epoch 1172 loss is 0.6686865091323853\n",
            "for epoch 1173 loss is 0.668677568435669\n",
            "for epoch 1174 loss is 0.6686686277389526\n",
            "for epoch 1175 loss is 0.6686595678329468\n",
            "for epoch 1176 loss is 0.6686506867408752\n",
            "for epoch 1177 loss is 0.6686417460441589\n",
            "for epoch 1178 loss is 0.6686328053474426\n",
            "for epoch 1179 loss is 0.6686238646507263\n",
            "for epoch 1180 loss is 0.6686149835586548\n",
            "for epoch 1181 loss is 0.668606162071228\n",
            "for epoch 1182 loss is 0.6685972213745117\n",
            "for epoch 1183 loss is 0.6685883402824402\n",
            "for epoch 1184 loss is 0.6685795783996582\n",
            "for epoch 1185 loss is 0.6685706973075867\n",
            "for epoch 1186 loss is 0.6685619354248047\n",
            "for epoch 1187 loss is 0.6685531139373779\n",
            "for epoch 1188 loss is 0.668544352054596\n",
            "for epoch 1189 loss is 0.6685356497764587\n",
            "for epoch 1190 loss is 0.6685267686843872\n",
            "for epoch 1191 loss is 0.6685181260108948\n",
            "for epoch 1192 loss is 0.6685093641281128\n",
            "for epoch 1193 loss is 0.6685007214546204\n",
            "for epoch 1194 loss is 0.6684919595718384\n",
            "for epoch 1195 loss is 0.6684833765029907\n",
            "for epoch 1196 loss is 0.6684746146202087\n",
            "for epoch 1197 loss is 0.6684659719467163\n",
            "for epoch 1198 loss is 0.6684573888778687\n",
            "for epoch 1199 loss is 0.6684486865997314\n",
            "for epoch 1200 loss is 0.6684401035308838\n",
            "for epoch 1201 loss is 0.6684315204620361\n",
            "for epoch 1202 loss is 0.6684228777885437\n",
            "for epoch 1203 loss is 0.6684144139289856\n",
            "for epoch 1204 loss is 0.6684058308601379\n",
            "for epoch 1205 loss is 0.6683972477912903\n",
            "for epoch 1206 loss is 0.6683887839317322\n",
            "for epoch 1207 loss is 0.6683802604675293\n",
            "for epoch 1208 loss is 0.6683717370033264\n",
            "for epoch 1209 loss is 0.6683632135391235\n",
            "for epoch 1210 loss is 0.6683547496795654\n",
            "for epoch 1211 loss is 0.6683463454246521\n",
            "for epoch 1212 loss is 0.6683379411697388\n",
            "for epoch 1213 loss is 0.6683293581008911\n",
            "for epoch 1214 loss is 0.6683210730552673\n",
            "for epoch 1215 loss is 0.6683126091957092\n",
            "for epoch 1216 loss is 0.6683042645454407\n",
            "for epoch 1217 loss is 0.6682958602905273\n",
            "for epoch 1218 loss is 0.6682875156402588\n",
            "for epoch 1219 loss is 0.6682791113853455\n",
            "for epoch 1220 loss is 0.6682708263397217\n",
            "for epoch 1221 loss is 0.6682625412940979\n",
            "for epoch 1222 loss is 0.6682541966438293\n",
            "for epoch 1223 loss is 0.6682458519935608\n",
            "for epoch 1224 loss is 0.6682376265525818\n",
            "for epoch 1225 loss is 0.6682292819023132\n",
            "for epoch 1226 loss is 0.6682210564613342\n",
            "for epoch 1227 loss is 0.6682128310203552\n",
            "for epoch 1228 loss is 0.6682046055793762\n",
            "for epoch 1229 loss is 0.6681963801383972\n",
            "for epoch 1230 loss is 0.6681881546974182\n",
            "for epoch 1231 loss is 0.6681800484657288\n",
            "for epoch 1232 loss is 0.6681718230247498\n",
            "for epoch 1233 loss is 0.6681636571884155\n",
            "for epoch 1234 loss is 0.6681555509567261\n",
            "for epoch 1235 loss is 0.6681473255157471\n",
            "for epoch 1236 loss is 0.6681392788887024\n",
            "for epoch 1237 loss is 0.6681311130523682\n",
            "for epoch 1238 loss is 0.6681229472160339\n",
            "for epoch 1239 loss is 0.6681149005889893\n",
            "for epoch 1240 loss is 0.6681067943572998\n",
            "for epoch 1241 loss is 0.6680988073348999\n",
            "for epoch 1242 loss is 0.6680907607078552\n",
            "for epoch 1243 loss is 0.6680827140808105\n",
            "for epoch 1244 loss is 0.6680746674537659\n",
            "for epoch 1245 loss is 0.668066680431366\n",
            "for epoch 1246 loss is 0.6680586338043213\n",
            "for epoch 1247 loss is 0.6680506467819214\n",
            "for epoch 1248 loss is 0.6680427193641663\n",
            "for epoch 1249 loss is 0.6680347323417664\n",
            "for epoch 1250 loss is 0.6680267453193665\n",
            "for epoch 1251 loss is 0.6680188775062561\n",
            "for epoch 1252 loss is 0.668010950088501\n",
            "for epoch 1253 loss is 0.6680030226707458\n",
            "for epoch 1254 loss is 0.6679950952529907\n",
            "for epoch 1255 loss is 0.6679872870445251\n",
            "for epoch 1256 loss is 0.66797935962677\n",
            "for epoch 1257 loss is 0.6679714918136597\n",
            "for epoch 1258 loss is 0.6679636240005493\n",
            "for epoch 1259 loss is 0.6679558753967285\n",
            "for epoch 1260 loss is 0.6679480671882629\n",
            "for epoch 1261 loss is 0.6679401397705078\n",
            "for epoch 1262 loss is 0.667932391166687\n",
            "for epoch 1263 loss is 0.6679245233535767\n",
            "for epoch 1264 loss is 0.6679167747497559\n",
            "for epoch 1265 loss is 0.6679090857505798\n",
            "for epoch 1266 loss is 0.6679012179374695\n",
            "for epoch 1267 loss is 0.6678935289382935\n",
            "for epoch 1268 loss is 0.6678858399391174\n",
            "for epoch 1269 loss is 0.6678780317306519\n",
            "for epoch 1270 loss is 0.6678703427314758\n",
            "for epoch 1271 loss is 0.6678626537322998\n",
            "for epoch 1272 loss is 0.6678549647331238\n",
            "for epoch 1273 loss is 0.6678473353385925\n",
            "for epoch 1274 loss is 0.6678397059440613\n",
            "for epoch 1275 loss is 0.6678320169448853\n",
            "for epoch 1276 loss is 0.667824387550354\n",
            "for epoch 1277 loss is 0.6678167581558228\n",
            "for epoch 1278 loss is 0.6678091287612915\n",
            "for epoch 1279 loss is 0.6678014993667603\n",
            "for epoch 1280 loss is 0.6677939891815186\n",
            "for epoch 1281 loss is 0.6677863597869873\n",
            "for epoch 1282 loss is 0.6677788496017456\n",
            "for epoch 1283 loss is 0.6677712798118591\n",
            "for epoch 1284 loss is 0.6677637100219727\n",
            "for epoch 1285 loss is 0.6677562594413757\n",
            "for epoch 1286 loss is 0.667748749256134\n",
            "for epoch 1287 loss is 0.6677412390708923\n",
            "for epoch 1288 loss is 0.6677336692810059\n",
            "for epoch 1289 loss is 0.6677262187004089\n",
            "for epoch 1290 loss is 0.6677187085151672\n",
            "for epoch 1291 loss is 0.6677111983299255\n",
            "for epoch 1292 loss is 0.6677038073539734\n",
            "for epoch 1293 loss is 0.6676963567733765\n",
            "for epoch 1294 loss is 0.6676889061927795\n",
            "for epoch 1295 loss is 0.6676815152168274\n",
            "for epoch 1296 loss is 0.6676740646362305\n",
            "for epoch 1297 loss is 0.6676666736602783\n",
            "for epoch 1298 loss is 0.667659342288971\n",
            "for epoch 1299 loss is 0.6676520109176636\n",
            "for epoch 1300 loss is 0.6676446199417114\n",
            "for epoch 1301 loss is 0.667637288570404\n",
            "for epoch 1302 loss is 0.6676298975944519\n",
            "for epoch 1303 loss is 0.6676226258277893\n",
            "for epoch 1304 loss is 0.6676151752471924\n",
            "for epoch 1305 loss is 0.6676079034805298\n",
            "for epoch 1306 loss is 0.667600691318512\n",
            "for epoch 1307 loss is 0.6675933599472046\n",
            "for epoch 1308 loss is 0.6675860285758972\n",
            "for epoch 1309 loss is 0.6675788164138794\n",
            "for epoch 1310 loss is 0.6675715446472168\n",
            "for epoch 1311 loss is 0.667564332485199\n",
            "for epoch 1312 loss is 0.6675571203231812\n",
            "for epoch 1313 loss is 0.6675499081611633\n",
            "for epoch 1314 loss is 0.6675426959991455\n",
            "for epoch 1315 loss is 0.6675354242324829\n",
            "for epoch 1316 loss is 0.6675282120704651\n",
            "for epoch 1317 loss is 0.667521059513092\n",
            "for epoch 1318 loss is 0.6675139665603638\n",
            "for epoch 1319 loss is 0.6675068140029907\n",
            "for epoch 1320 loss is 0.6674997210502625\n",
            "for epoch 1321 loss is 0.6674925088882446\n",
            "for epoch 1322 loss is 0.6674854159355164\n",
            "for epoch 1323 loss is 0.6674782633781433\n",
            "for epoch 1324 loss is 0.6674712300300598\n",
            "for epoch 1325 loss is 0.6674640774726868\n",
            "for epoch 1326 loss is 0.6674569845199585\n",
            "for epoch 1327 loss is 0.667449951171875\n",
            "for epoch 1328 loss is 0.6674429178237915\n",
            "for epoch 1329 loss is 0.6674357652664185\n",
            "for epoch 1330 loss is 0.6674288511276245\n",
            "for epoch 1331 loss is 0.667421817779541\n",
            "for epoch 1332 loss is 0.6674147248268127\n",
            "for epoch 1333 loss is 0.6674076914787292\n",
            "for epoch 1334 loss is 0.6674007773399353\n",
            "for epoch 1335 loss is 0.6673938035964966\n",
            "for epoch 1336 loss is 0.6673867702484131\n",
            "for epoch 1337 loss is 0.6673798561096191\n",
            "for epoch 1338 loss is 0.6673728227615356\n",
            "for epoch 1339 loss is 0.6673659682273865\n",
            "for epoch 1340 loss is 0.6673589944839478\n",
            "for epoch 1341 loss is 0.6673520803451538\n",
            "for epoch 1342 loss is 0.6673451066017151\n",
            "for epoch 1343 loss is 0.6673381924629211\n",
            "for epoch 1344 loss is 0.667331337928772\n",
            "for epoch 1345 loss is 0.667324423789978\n",
            "for epoch 1346 loss is 0.6673175692558289\n",
            "for epoch 1347 loss is 0.6673107743263245\n",
            "for epoch 1348 loss is 0.6673038601875305\n",
            "for epoch 1349 loss is 0.6672969460487366\n",
            "for epoch 1350 loss is 0.667290210723877\n",
            "for epoch 1351 loss is 0.6672834157943726\n",
            "for epoch 1352 loss is 0.6672766208648682\n",
            "for epoch 1353 loss is 0.6672697067260742\n",
            "for epoch 1354 loss is 0.6672629117965698\n",
            "for epoch 1355 loss is 0.6672561168670654\n",
            "for epoch 1356 loss is 0.667249321937561\n",
            "for epoch 1357 loss is 0.6672426462173462\n",
            "for epoch 1358 loss is 0.6672359108924866\n",
            "for epoch 1359 loss is 0.6672291159629822\n",
            "for epoch 1360 loss is 0.6672223210334778\n",
            "for epoch 1361 loss is 0.6672157049179077\n",
            "for epoch 1362 loss is 0.6672089099884033\n",
            "for epoch 1363 loss is 0.6672021746635437\n",
            "for epoch 1364 loss is 0.6671955585479736\n",
            "for epoch 1365 loss is 0.6671888828277588\n",
            "for epoch 1366 loss is 0.667182207107544\n",
            "for epoch 1367 loss is 0.6671755313873291\n",
            "for epoch 1368 loss is 0.667168915271759\n",
            "for epoch 1369 loss is 0.6671621799468994\n",
            "for epoch 1370 loss is 0.6671555638313293\n",
            "for epoch 1371 loss is 0.6671488881111145\n",
            "for epoch 1372 loss is 0.6671423316001892\n",
            "for epoch 1373 loss is 0.6671357750892639\n",
            "for epoch 1374 loss is 0.6671292185783386\n",
            "for epoch 1375 loss is 0.6671225428581238\n",
            "for epoch 1376 loss is 0.6671159267425537\n",
            "for epoch 1377 loss is 0.6671093702316284\n",
            "for epoch 1378 loss is 0.6671028733253479\n",
            "for epoch 1379 loss is 0.6670963168144226\n",
            "for epoch 1380 loss is 0.6670897006988525\n",
            "for epoch 1381 loss is 0.6670831441879272\n",
            "for epoch 1382 loss is 0.6670766472816467\n",
            "for epoch 1383 loss is 0.6670701503753662\n",
            "for epoch 1384 loss is 0.6670635938644409\n",
            "for epoch 1385 loss is 0.6670570969581604\n",
            "for epoch 1386 loss is 0.6670507192611694\n",
            "for epoch 1387 loss is 0.6670441627502441\n",
            "for epoch 1388 loss is 0.6670377254486084\n",
            "for epoch 1389 loss is 0.6670312285423279\n",
            "for epoch 1390 loss is 0.6670247316360474\n",
            "for epoch 1391 loss is 0.6670183539390564\n",
            "for epoch 1392 loss is 0.6670119166374207\n",
            "for epoch 1393 loss is 0.6670054793357849\n",
            "for epoch 1394 loss is 0.6669989824295044\n",
            "for epoch 1395 loss is 0.6669926643371582\n",
            "for epoch 1396 loss is 0.6669862270355225\n",
            "for epoch 1397 loss is 0.666979968547821\n",
            "for epoch 1398 loss is 0.6669735908508301\n",
            "for epoch 1399 loss is 0.6669671535491943\n",
            "for epoch 1400 loss is 0.6669608354568481\n",
            "for epoch 1401 loss is 0.6669544577598572\n",
            "for epoch 1402 loss is 0.6669480800628662\n",
            "for epoch 1403 loss is 0.6669418215751648\n",
            "for epoch 1404 loss is 0.666935384273529\n",
            "for epoch 1405 loss is 0.6669291257858276\n",
            "for epoch 1406 loss is 0.666922926902771\n",
            "for epoch 1407 loss is 0.6669164896011353\n",
            "for epoch 1408 loss is 0.6669103503227234\n",
            "for epoch 1409 loss is 0.6669039726257324\n",
            "for epoch 1410 loss is 0.666897714138031\n",
            "for epoch 1411 loss is 0.6668913960456848\n",
            "for epoch 1412 loss is 0.6668851971626282\n",
            "for epoch 1413 loss is 0.6668789386749268\n",
            "for epoch 1414 loss is 0.6668726801872253\n",
            "for epoch 1415 loss is 0.6668664813041687\n",
            "for epoch 1416 loss is 0.6668602824211121\n",
            "for epoch 1417 loss is 0.6668540239334106\n",
            "for epoch 1418 loss is 0.666847825050354\n",
            "for epoch 1419 loss is 0.6668417453765869\n",
            "for epoch 1420 loss is 0.6668355464935303\n",
            "for epoch 1421 loss is 0.6668292880058289\n",
            "for epoch 1422 loss is 0.666823148727417\n",
            "for epoch 1423 loss is 0.6668169498443604\n",
            "for epoch 1424 loss is 0.6668108701705933\n",
            "for epoch 1425 loss is 0.6668047308921814\n",
            "for epoch 1426 loss is 0.6667985320091248\n",
            "for epoch 1427 loss is 0.6667925119400024\n",
            "for epoch 1428 loss is 0.6667863726615906\n",
            "for epoch 1429 loss is 0.6667802929878235\n",
            "for epoch 1430 loss is 0.6667740941047668\n",
            "for epoch 1431 loss is 0.6667680740356445\n",
            "for epoch 1432 loss is 0.6667619943618774\n",
            "for epoch 1433 loss is 0.6667559146881104\n",
            "for epoch 1434 loss is 0.6667499542236328\n",
            "for epoch 1435 loss is 0.666743814945221\n",
            "for epoch 1436 loss is 0.6667377948760986\n",
            "for epoch 1437 loss is 0.6667317748069763\n",
            "for epoch 1438 loss is 0.6667256951332092\n",
            "for epoch 1439 loss is 0.6667196750640869\n",
            "for epoch 1440 loss is 0.6667137145996094\n",
            "for epoch 1441 loss is 0.6667076945304871\n",
            "for epoch 1442 loss is 0.6667017340660095\n",
            "for epoch 1443 loss is 0.666695773601532\n",
            "for epoch 1444 loss is 0.6666896939277649\n",
            "for epoch 1445 loss is 0.6666837334632874\n",
            "for epoch 1446 loss is 0.6666777729988098\n",
            "for epoch 1447 loss is 0.6666718125343323\n",
            "for epoch 1448 loss is 0.6666659116744995\n",
            "for epoch 1449 loss is 0.666659951210022\n",
            "for epoch 1450 loss is 0.6666539907455444\n",
            "for epoch 1451 loss is 0.6666481494903564\n",
            "for epoch 1452 loss is 0.6666421890258789\n",
            "for epoch 1453 loss is 0.6666362881660461\n",
            "for epoch 1454 loss is 0.6666303873062134\n",
            "for epoch 1455 loss is 0.6666246056556702\n",
            "for epoch 1456 loss is 0.6666185259819031\n",
            "for epoch 1457 loss is 0.6666128039360046\n",
            "for epoch 1458 loss is 0.6666069030761719\n",
            "for epoch 1459 loss is 0.6666010022163391\n",
            "for epoch 1460 loss is 0.6665952205657959\n",
            "for epoch 1461 loss is 0.6665893197059631\n",
            "for epoch 1462 loss is 0.6665835380554199\n",
            "for epoch 1463 loss is 0.6665777564048767\n",
            "for epoch 1464 loss is 0.6665719151496887\n",
            "for epoch 1465 loss is 0.6665660738945007\n",
            "for epoch 1466 loss is 0.6665602922439575\n",
            "for epoch 1467 loss is 0.6665545105934143\n",
            "for epoch 1468 loss is 0.6665487289428711\n",
            "for epoch 1469 loss is 0.6665430068969727\n",
            "for epoch 1470 loss is 0.6665372252464294\n",
            "for epoch 1471 loss is 0.6665314435958862\n",
            "for epoch 1472 loss is 0.6665256023406982\n",
            "for epoch 1473 loss is 0.6665198802947998\n",
            "for epoch 1474 loss is 0.6665141582489014\n",
            "for epoch 1475 loss is 0.6665084958076477\n",
            "for epoch 1476 loss is 0.6665027737617493\n",
            "for epoch 1477 loss is 0.6664971113204956\n",
            "for epoch 1478 loss is 0.6664913892745972\n",
            "for epoch 1479 loss is 0.666485607624054\n",
            "for epoch 1480 loss is 0.6664799451828003\n",
            "for epoch 1481 loss is 0.6664742827415466\n",
            "for epoch 1482 loss is 0.666468620300293\n",
            "for epoch 1483 loss is 0.6664629578590393\n",
            "for epoch 1484 loss is 0.6664574146270752\n",
            "for epoch 1485 loss is 0.6664516925811768\n",
            "for epoch 1486 loss is 0.6664460301399231\n",
            "for epoch 1487 loss is 0.6664403676986694\n",
            "for epoch 1488 loss is 0.6664347648620605\n",
            "for epoch 1489 loss is 0.6664291620254517\n",
            "for epoch 1490 loss is 0.6664236187934875\n",
            "for epoch 1491 loss is 0.6664179563522339\n",
            "for epoch 1492 loss is 0.6664122939109802\n",
            "for epoch 1493 loss is 0.6664066910743713\n",
            "for epoch 1494 loss is 0.6664010882377625\n",
            "for epoch 1495 loss is 0.6663956642150879\n",
            "for epoch 1496 loss is 0.666390061378479\n",
            "for epoch 1497 loss is 0.6663845181465149\n",
            "for epoch 1498 loss is 0.666378915309906\n",
            "for epoch 1499 loss is 0.6663733720779419\n",
            "for epoch 1500 loss is 0.6663678884506226\n",
            "for epoch 1501 loss is 0.6663622856140137\n",
            "for epoch 1502 loss is 0.6663568019866943\n",
            "for epoch 1503 loss is 0.6663513779640198\n",
            "for epoch 1504 loss is 0.6663458347320557\n",
            "for epoch 1505 loss is 0.6663402915000916\n",
            "for epoch 1506 loss is 0.6663348078727722\n",
            "for epoch 1507 loss is 0.6663293838500977\n",
            "for epoch 1508 loss is 0.6663239002227783\n",
            "for epoch 1509 loss is 0.6663183569908142\n",
            "for epoch 1510 loss is 0.6663129329681396\n",
            "for epoch 1511 loss is 0.6663075089454651\n",
            "for epoch 1512 loss is 0.6663020849227905\n",
            "for epoch 1513 loss is 0.6662965416908264\n",
            "for epoch 1514 loss is 0.6662912368774414\n",
            "for epoch 1515 loss is 0.6662857532501221\n",
            "for epoch 1516 loss is 0.6662803292274475\n",
            "for epoch 1517 loss is 0.666274905204773\n",
            "for epoch 1518 loss is 0.6662695407867432\n",
            "for epoch 1519 loss is 0.6662641167640686\n",
            "for epoch 1520 loss is 0.6662587523460388\n",
            "for epoch 1521 loss is 0.6662533283233643\n",
            "for epoch 1522 loss is 0.6662480235099792\n",
            "for epoch 1523 loss is 0.6662425994873047\n",
            "for epoch 1524 loss is 0.6662372946739197\n",
            "for epoch 1525 loss is 0.6662319898605347\n",
            "for epoch 1526 loss is 0.6662265062332153\n",
            "for epoch 1527 loss is 0.6662213206291199\n",
            "for epoch 1528 loss is 0.6662159562110901\n",
            "for epoch 1529 loss is 0.6662105917930603\n",
            "for epoch 1530 loss is 0.6662053465843201\n",
            "for epoch 1531 loss is 0.6661999821662903\n",
            "for epoch 1532 loss is 0.6661946773529053\n",
            "for epoch 1533 loss is 0.6661893725395203\n",
            "for epoch 1534 loss is 0.6661840081214905\n",
            "for epoch 1535 loss is 0.6661788821220398\n",
            "for epoch 1536 loss is 0.66617351770401\n",
            "for epoch 1537 loss is 0.6661682724952698\n",
            "for epoch 1538 loss is 0.6661629676818848\n",
            "for epoch 1539 loss is 0.6661577820777893\n",
            "for epoch 1540 loss is 0.6661525368690491\n",
            "for epoch 1541 loss is 0.6661472916603088\n",
            "for epoch 1542 loss is 0.6661420464515686\n",
            "for epoch 1543 loss is 0.6661368608474731\n",
            "for epoch 1544 loss is 0.6661316752433777\n",
            "for epoch 1545 loss is 0.6661264300346375\n",
            "for epoch 1546 loss is 0.6661211848258972\n",
            "for epoch 1547 loss is 0.6661160588264465\n",
            "for epoch 1548 loss is 0.6661108136177063\n",
            "for epoch 1549 loss is 0.6661056876182556\n",
            "for epoch 1550 loss is 0.6661005020141602\n",
            "for epoch 1551 loss is 0.6660952568054199\n",
            "for epoch 1552 loss is 0.6660902500152588\n",
            "for epoch 1553 loss is 0.6660850048065186\n",
            "for epoch 1554 loss is 0.6660798192024231\n",
            "for epoch 1555 loss is 0.6660747528076172\n",
            "for epoch 1556 loss is 0.6660696268081665\n",
            "for epoch 1557 loss is 0.6660645008087158\n",
            "for epoch 1558 loss is 0.6660593748092651\n",
            "for epoch 1559 loss is 0.6660542488098145\n",
            "for epoch 1560 loss is 0.666049063205719\n",
            "for epoch 1561 loss is 0.6660441160202026\n",
            "for epoch 1562 loss is 0.6660388708114624\n",
            "for epoch 1563 loss is 0.6660338640213013\n",
            "for epoch 1564 loss is 0.6660287976264954\n",
            "for epoch 1565 loss is 0.6660237312316895\n",
            "for epoch 1566 loss is 0.6660186648368835\n",
            "for epoch 1567 loss is 0.6660135388374329\n",
            "for epoch 1568 loss is 0.6660085320472717\n",
            "for epoch 1569 loss is 0.6660035252571106\n",
            "for epoch 1570 loss is 0.6659985184669495\n",
            "for epoch 1571 loss is 0.6659934520721436\n",
            "for epoch 1572 loss is 0.6659883856773376\n",
            "for epoch 1573 loss is 0.6659833788871765\n",
            "for epoch 1574 loss is 0.6659783720970154\n",
            "for epoch 1575 loss is 0.6659733653068542\n",
            "for epoch 1576 loss is 0.6659683585166931\n",
            "for epoch 1577 loss is 0.665963351726532\n",
            "for epoch 1578 loss is 0.6659583449363708\n",
            "for epoch 1579 loss is 0.6659533977508545\n",
            "for epoch 1580 loss is 0.6659483909606934\n",
            "for epoch 1581 loss is 0.6659435033798218\n",
            "for epoch 1582 loss is 0.6659384965896606\n",
            "for epoch 1583 loss is 0.6659335494041443\n",
            "for epoch 1584 loss is 0.6659286022186279\n",
            "for epoch 1585 loss is 0.6659236550331116\n",
            "for epoch 1586 loss is 0.66591876745224\n",
            "for epoch 1587 loss is 0.6659138202667236\n",
            "for epoch 1588 loss is 0.6659088730812073\n",
            "for epoch 1589 loss is 0.6659039258956909\n",
            "for epoch 1590 loss is 0.6658990383148193\n",
            "for epoch 1591 loss is 0.6658941507339478\n",
            "for epoch 1592 loss is 0.6658892631530762\n",
            "for epoch 1593 loss is 0.6658843755722046\n",
            "for epoch 1594 loss is 0.6658794283866882\n",
            "for epoch 1595 loss is 0.6658746004104614\n",
            "for epoch 1596 loss is 0.6658697724342346\n",
            "for epoch 1597 loss is 0.665864884853363\n",
            "for epoch 1598 loss is 0.6658599376678467\n",
            "for epoch 1599 loss is 0.6658551096916199\n",
            "for epoch 1600 loss is 0.6658502817153931\n",
            "for epoch 1601 loss is 0.665845513343811\n",
            "for epoch 1602 loss is 0.6658406853675842\n",
            "for epoch 1603 loss is 0.6658357977867126\n",
            "for epoch 1604 loss is 0.6658309698104858\n",
            "for epoch 1605 loss is 0.6658262014389038\n",
            "for epoch 1606 loss is 0.6658214330673218\n",
            "for epoch 1607 loss is 0.6658165454864502\n",
            "for epoch 1608 loss is 0.6658117771148682\n",
            "for epoch 1609 loss is 0.6658070683479309\n",
            "for epoch 1610 loss is 0.6658022403717041\n",
            "for epoch 1611 loss is 0.6657974720001221\n",
            "for epoch 1612 loss is 0.6657926440238953\n",
            "for epoch 1613 loss is 0.665787935256958\n",
            "for epoch 1614 loss is 0.665783166885376\n",
            "for epoch 1615 loss is 0.6657784581184387\n",
            "for epoch 1616 loss is 0.6657736897468567\n",
            "for epoch 1617 loss is 0.6657689213752747\n",
            "for epoch 1618 loss is 0.6657642722129822\n",
            "for epoch 1619 loss is 0.6657595038414001\n",
            "for epoch 1620 loss is 0.6657547354698181\n",
            "for epoch 1621 loss is 0.6657500863075256\n",
            "for epoch 1622 loss is 0.6657452583312988\n",
            "for epoch 1623 loss is 0.6657406091690063\n",
            "for epoch 1624 loss is 0.6657359600067139\n",
            "for epoch 1625 loss is 0.6657312512397766\n",
            "for epoch 1626 loss is 0.6657264828681946\n",
            "for epoch 1627 loss is 0.6657218337059021\n",
            "for epoch 1628 loss is 0.6657172441482544\n",
            "for epoch 1629 loss is 0.6657124757766724\n",
            "for epoch 1630 loss is 0.6657077670097351\n",
            "for epoch 1631 loss is 0.6657031774520874\n",
            "for epoch 1632 loss is 0.6656985878944397\n",
            "for epoch 1633 loss is 0.665693998336792\n",
            "for epoch 1634 loss is 0.6656892895698547\n",
            "for epoch 1635 loss is 0.665684700012207\n",
            "for epoch 1636 loss is 0.6656799912452698\n",
            "for epoch 1637 loss is 0.6656753420829773\n",
            "for epoch 1638 loss is 0.6656708121299744\n",
            "for epoch 1639 loss is 0.6656661629676819\n",
            "for epoch 1640 loss is 0.6656616926193237\n",
            "for epoch 1641 loss is 0.665657103061676\n",
            "for epoch 1642 loss is 0.6656524538993835\n",
            "for epoch 1643 loss is 0.6656478643417358\n",
            "for epoch 1644 loss is 0.6656433343887329\n",
            "for epoch 1645 loss is 0.6656387448310852\n",
            "for epoch 1646 loss is 0.6656341552734375\n",
            "for epoch 1647 loss is 0.6656296253204346\n",
            "for epoch 1648 loss is 0.6656250953674316\n",
            "for epoch 1649 loss is 0.6656205654144287\n",
            "for epoch 1650 loss is 0.6656160354614258\n",
            "for epoch 1651 loss is 0.6656113862991333\n",
            "for epoch 1652 loss is 0.6656069159507751\n",
            "for epoch 1653 loss is 0.665602445602417\n",
            "for epoch 1654 loss is 0.6655979156494141\n",
            "for epoch 1655 loss is 0.6655933856964111\n",
            "for epoch 1656 loss is 0.6655888557434082\n",
            "for epoch 1657 loss is 0.6655843257904053\n",
            "for epoch 1658 loss is 0.6655798554420471\n",
            "for epoch 1659 loss is 0.6655753254890442\n",
            "for epoch 1660 loss is 0.6655709147453308\n",
            "for epoch 1661 loss is 0.6655663847923279\n",
            "for epoch 1662 loss is 0.6655619740486145\n",
            "for epoch 1663 loss is 0.6655574440956116\n",
            "for epoch 1664 loss is 0.6655529737472534\n",
            "for epoch 1665 loss is 0.6655486226081848\n",
            "for epoch 1666 loss is 0.6655440926551819\n",
            "for epoch 1667 loss is 0.6655397415161133\n",
            "for epoch 1668 loss is 0.6655352115631104\n",
            "for epoch 1669 loss is 0.665530800819397\n",
            "for epoch 1670 loss is 0.6655264496803284\n",
            "for epoch 1671 loss is 0.6655219197273254\n",
            "for epoch 1672 loss is 0.6655176281929016\n",
            "for epoch 1673 loss is 0.6655130982398987\n",
            "for epoch 1674 loss is 0.6655086874961853\n",
            "for epoch 1675 loss is 0.6655043363571167\n",
            "for epoch 1676 loss is 0.6654999256134033\n",
            "for epoch 1677 loss is 0.6654955744743347\n",
            "for epoch 1678 loss is 0.6654911637306213\n",
            "for epoch 1679 loss is 0.6654868125915527\n",
            "for epoch 1680 loss is 0.6654824018478394\n",
            "for epoch 1681 loss is 0.6654780507087708\n",
            "for epoch 1682 loss is 0.6654736995697021\n",
            "for epoch 1683 loss is 0.6654694676399231\n",
            "for epoch 1684 loss is 0.6654649972915649\n",
            "for epoch 1685 loss is 0.6654607057571411\n",
            "for epoch 1686 loss is 0.6654562950134277\n",
            "for epoch 1687 loss is 0.6654520034790039\n",
            "for epoch 1688 loss is 0.6654476523399353\n",
            "for epoch 1689 loss is 0.6654433608055115\n",
            "for epoch 1690 loss is 0.6654390096664429\n",
            "for epoch 1691 loss is 0.6654346585273743\n",
            "for epoch 1692 loss is 0.6654304265975952\n",
            "for epoch 1693 loss is 0.6654260754585266\n",
            "for epoch 1694 loss is 0.6654218435287476\n",
            "for epoch 1695 loss is 0.665417492389679\n",
            "for epoch 1696 loss is 0.6654133200645447\n",
            "for epoch 1697 loss is 0.6654089689254761\n",
            "for epoch 1698 loss is 0.6654046773910522\n",
            "for epoch 1699 loss is 0.6654003858566284\n",
            "for epoch 1700 loss is 0.6653960943222046\n",
            "for epoch 1701 loss is 0.6653919219970703\n",
            "for epoch 1702 loss is 0.6653876304626465\n",
            "for epoch 1703 loss is 0.6653833985328674\n",
            "for epoch 1704 loss is 0.6653791666030884\n",
            "for epoch 1705 loss is 0.6653748750686646\n",
            "for epoch 1706 loss is 0.6653707027435303\n",
            "for epoch 1707 loss is 0.665366530418396\n",
            "for epoch 1708 loss is 0.6653622984886169\n",
            "for epoch 1709 loss is 0.6653580665588379\n",
            "for epoch 1710 loss is 0.6653538346290588\n",
            "for epoch 1711 loss is 0.6653496623039246\n",
            "for epoch 1712 loss is 0.6653455495834351\n",
            "for epoch 1713 loss is 0.6653411984443665\n",
            "for epoch 1714 loss is 0.665337085723877\n",
            "for epoch 1715 loss is 0.6653329133987427\n",
            "for epoch 1716 loss is 0.6653287410736084\n",
            "for epoch 1717 loss is 0.6653245091438293\n",
            "for epoch 1718 loss is 0.6653204560279846\n",
            "for epoch 1719 loss is 0.6653162240982056\n",
            "for epoch 1720 loss is 0.6653119921684265\n",
            "for epoch 1721 loss is 0.6653079390525818\n",
            "for epoch 1722 loss is 0.6653037667274475\n",
            "for epoch 1723 loss is 0.665299654006958\n",
            "for epoch 1724 loss is 0.6652954816818237\n",
            "for epoch 1725 loss is 0.6652913093566895\n",
            "for epoch 1726 loss is 0.6652872562408447\n",
            "for epoch 1727 loss is 0.6652830839157104\n",
            "for epoch 1728 loss is 0.6652790307998657\n",
            "for epoch 1729 loss is 0.6652748584747314\n",
            "for epoch 1730 loss is 0.6652708053588867\n",
            "for epoch 1731 loss is 0.665266752243042\n",
            "for epoch 1732 loss is 0.6652626395225525\n",
            "for epoch 1733 loss is 0.665258526802063\n",
            "for epoch 1734 loss is 0.6652544140815735\n",
            "for epoch 1735 loss is 0.6652503609657288\n",
            "for epoch 1736 loss is 0.6652462482452393\n",
            "for epoch 1737 loss is 0.6652422547340393\n",
            "for epoch 1738 loss is 0.6652381420135498\n",
            "for epoch 1739 loss is 0.6652341485023499\n",
            "for epoch 1740 loss is 0.6652300357818604\n",
            "for epoch 1741 loss is 0.6652259826660156\n",
            "for epoch 1742 loss is 0.6652218699455261\n",
            "for epoch 1743 loss is 0.6652179956436157\n",
            "for epoch 1744 loss is 0.6652138829231262\n",
            "for epoch 1745 loss is 0.6652098894119263\n",
            "for epoch 1746 loss is 0.6652058362960815\n",
            "for epoch 1747 loss is 0.6652018427848816\n",
            "for epoch 1748 loss is 0.6651977896690369\n",
            "for epoch 1749 loss is 0.6651937961578369\n",
            "for epoch 1750 loss is 0.665189802646637\n",
            "for epoch 1751 loss is 0.665185809135437\n",
            "for epoch 1752 loss is 0.6651818156242371\n",
            "for epoch 1753 loss is 0.6651778221130371\n",
            "for epoch 1754 loss is 0.6651738286018372\n",
            "for epoch 1755 loss is 0.6651698350906372\n",
            "for epoch 1756 loss is 0.665165901184082\n",
            "for epoch 1757 loss is 0.6651617884635925\n",
            "for epoch 1758 loss is 0.6651579737663269\n",
            "for epoch 1759 loss is 0.6651540398597717\n",
            "for epoch 1760 loss is 0.6651500463485718\n",
            "for epoch 1761 loss is 0.6651461124420166\n",
            "for epoch 1762 loss is 0.6651421189308167\n",
            "for epoch 1763 loss is 0.6651381850242615\n",
            "for epoch 1764 loss is 0.6651341915130615\n",
            "for epoch 1765 loss is 0.6651302576065063\n",
            "for epoch 1766 loss is 0.6651264429092407\n",
            "for epoch 1767 loss is 0.6651225090026855\n",
            "for epoch 1768 loss is 0.6651185750961304\n",
            "for epoch 1769 loss is 0.66511470079422\n",
            "for epoch 1770 loss is 0.6651107668876648\n",
            "for epoch 1771 loss is 0.6651068925857544\n",
            "for epoch 1772 loss is 0.665103018283844\n",
            "for epoch 1773 loss is 0.6650990843772888\n",
            "for epoch 1774 loss is 0.6650952696800232\n",
            "for epoch 1775 loss is 0.665091335773468\n",
            "for epoch 1776 loss is 0.6650874018669128\n",
            "for epoch 1777 loss is 0.665083646774292\n",
            "for epoch 1778 loss is 0.6650797128677368\n",
            "for epoch 1779 loss is 0.6650758385658264\n",
            "for epoch 1780 loss is 0.6650720238685608\n",
            "for epoch 1781 loss is 0.6650681495666504\n",
            "for epoch 1782 loss is 0.66506427526474\n",
            "for epoch 1783 loss is 0.6650604605674744\n",
            "for epoch 1784 loss is 0.665056586265564\n",
            "for epoch 1785 loss is 0.6650527715682983\n",
            "for epoch 1786 loss is 0.6650489568710327\n",
            "for epoch 1787 loss is 0.6650451421737671\n",
            "for epoch 1788 loss is 0.6650412678718567\n",
            "for epoch 1789 loss is 0.6650375127792358\n",
            "for epoch 1790 loss is 0.665033757686615\n",
            "for epoch 1791 loss is 0.6650298833847046\n",
            "for epoch 1792 loss is 0.6650261282920837\n",
            "for epoch 1793 loss is 0.6650223135948181\n",
            "for epoch 1794 loss is 0.6650185585021973\n",
            "for epoch 1795 loss is 0.6650146245956421\n",
            "for epoch 1796 loss is 0.665010929107666\n",
            "for epoch 1797 loss is 0.6650072336196899\n",
            "for epoch 1798 loss is 0.6650034189224243\n",
            "for epoch 1799 loss is 0.6649996042251587\n",
            "for epoch 1800 loss is 0.6649959087371826\n",
            "for epoch 1801 loss is 0.664992094039917\n",
            "for epoch 1802 loss is 0.6649883985519409\n",
            "for epoch 1803 loss is 0.6649845838546753\n",
            "for epoch 1804 loss is 0.6649808287620544\n",
            "for epoch 1805 loss is 0.6649771332740784\n",
            "for epoch 1806 loss is 0.6649733781814575\n",
            "for epoch 1807 loss is 0.6649696826934814\n",
            "for epoch 1808 loss is 0.6649659872055054\n",
            "for epoch 1809 loss is 0.6649621725082397\n",
            "for epoch 1810 loss is 0.6649584174156189\n",
            "for epoch 1811 loss is 0.6649547815322876\n",
            "for epoch 1812 loss is 0.6649510264396667\n",
            "for epoch 1813 loss is 0.6649473905563354\n",
            "for epoch 1814 loss is 0.6649436950683594\n",
            "for epoch 1815 loss is 0.6649399995803833\n",
            "for epoch 1816 loss is 0.6649363040924072\n",
            "for epoch 1817 loss is 0.6649326086044312\n",
            "for epoch 1818 loss is 0.6649289131164551\n",
            "for epoch 1819 loss is 0.664925217628479\n",
            "for epoch 1820 loss is 0.6649215221405029\n",
            "for epoch 1821 loss is 0.6649178862571716\n",
            "for epoch 1822 loss is 0.6649142503738403\n",
            "for epoch 1823 loss is 0.6649105548858643\n",
            "for epoch 1824 loss is 0.664906919002533\n",
            "for epoch 1825 loss is 0.6649032235145569\n",
            "for epoch 1826 loss is 0.6648996472358704\n",
            "for epoch 1827 loss is 0.6648960113525391\n",
            "for epoch 1828 loss is 0.664892315864563\n",
            "for epoch 1829 loss is 0.6648886799812317\n",
            "for epoch 1830 loss is 0.6648850440979004\n",
            "for epoch 1831 loss is 0.6648815274238586\n",
            "for epoch 1832 loss is 0.6648778319358826\n",
            "for epoch 1833 loss is 0.664874255657196\n",
            "for epoch 1834 loss is 0.6648706197738647\n",
            "for epoch 1835 loss is 0.664867103099823\n",
            "for epoch 1836 loss is 0.6648634076118469\n",
            "for epoch 1837 loss is 0.6648598313331604\n",
            "for epoch 1838 loss is 0.6648561954498291\n",
            "for epoch 1839 loss is 0.6648526787757874\n",
            "for epoch 1840 loss is 0.664849042892456\n",
            "for epoch 1841 loss is 0.6648454070091248\n",
            "for epoch 1842 loss is 0.664841890335083\n",
            "for epoch 1843 loss is 0.6648383140563965\n",
            "for epoch 1844 loss is 0.6648347973823547\n",
            "for epoch 1845 loss is 0.6648311614990234\n",
            "for epoch 1846 loss is 0.6648276448249817\n",
            "for epoch 1847 loss is 0.6648240685462952\n",
            "for epoch 1848 loss is 0.6648206114768982\n",
            "for epoch 1849 loss is 0.6648170351982117\n",
            "for epoch 1850 loss is 0.6648133993148804\n",
            "for epoch 1851 loss is 0.6648098826408386\n",
            "for epoch 1852 loss is 0.6648063063621521\n",
            "for epoch 1853 loss is 0.6648028492927551\n",
            "for epoch 1854 loss is 0.6647993326187134\n",
            "for epoch 1855 loss is 0.6647957563400269\n",
            "for epoch 1856 loss is 0.6647922396659851\n",
            "for epoch 1857 loss is 0.6647887229919434\n",
            "for epoch 1858 loss is 0.6647852063179016\n",
            "for epoch 1859 loss is 0.6647818088531494\n",
            "for epoch 1860 loss is 0.6647782325744629\n",
            "for epoch 1861 loss is 0.6647747755050659\n",
            "for epoch 1862 loss is 0.664771318435669\n",
            "for epoch 1863 loss is 0.664767861366272\n",
            "for epoch 1864 loss is 0.6647642850875854\n",
            "for epoch 1865 loss is 0.6647607684135437\n",
            "for epoch 1866 loss is 0.6647574305534363\n",
            "for epoch 1867 loss is 0.6647538542747498\n",
            "for epoch 1868 loss is 0.6647503972053528\n",
            "for epoch 1869 loss is 0.6647469401359558\n",
            "for epoch 1870 loss is 0.6647435426712036\n",
            "for epoch 1871 loss is 0.6647400856018066\n",
            "for epoch 1872 loss is 0.6647365689277649\n",
            "for epoch 1873 loss is 0.6647331714630127\n",
            "for epoch 1874 loss is 0.664729654788971\n",
            "for epoch 1875 loss is 0.6647262573242188\n",
            "for epoch 1876 loss is 0.6647228002548218\n",
            "for epoch 1877 loss is 0.6647194623947144\n",
            "for epoch 1878 loss is 0.6647160053253174\n",
            "for epoch 1879 loss is 0.6647125482559204\n",
            "for epoch 1880 loss is 0.664709210395813\n",
            "for epoch 1881 loss is 0.664705753326416\n",
            "for epoch 1882 loss is 0.6647023558616638\n",
            "for epoch 1883 loss is 0.6646988391876221\n",
            "for epoch 1884 loss is 0.6646955609321594\n",
            "for epoch 1885 loss is 0.6646921634674072\n",
            "for epoch 1886 loss is 0.664688766002655\n",
            "for epoch 1887 loss is 0.6646854281425476\n",
            "for epoch 1888 loss is 0.6646819710731506\n",
            "for epoch 1889 loss is 0.6646786332130432\n",
            "for epoch 1890 loss is 0.664675235748291\n",
            "for epoch 1891 loss is 0.6646718382835388\n",
            "for epoch 1892 loss is 0.6646684408187866\n",
            "for epoch 1893 loss is 0.6646651029586792\n",
            "for epoch 1894 loss is 0.664661705493927\n",
            "for epoch 1895 loss is 0.6646584272384644\n",
            "for epoch 1896 loss is 0.6646550893783569\n",
            "for epoch 1897 loss is 0.6646517515182495\n",
            "for epoch 1898 loss is 0.6646483540534973\n",
            "for epoch 1899 loss is 0.6646450161933899\n",
            "for epoch 1900 loss is 0.6646417379379272\n",
            "for epoch 1901 loss is 0.664638340473175\n",
            "for epoch 1902 loss is 0.6646350026130676\n",
            "for epoch 1903 loss is 0.6646316647529602\n",
            "for epoch 1904 loss is 0.6646283864974976\n",
            "for epoch 1905 loss is 0.6646250486373901\n",
            "for epoch 1906 loss is 0.6646217107772827\n",
            "for epoch 1907 loss is 0.6646184325218201\n",
            "for epoch 1908 loss is 0.6646151542663574\n",
            "for epoch 1909 loss is 0.66461181640625\n",
            "for epoch 1910 loss is 0.6646085381507874\n",
            "for epoch 1911 loss is 0.6646053194999695\n",
            "for epoch 1912 loss is 0.6646019220352173\n",
            "for epoch 1913 loss is 0.6645987033843994\n",
            "for epoch 1914 loss is 0.6645954847335815\n",
            "for epoch 1915 loss is 0.6645921468734741\n",
            "for epoch 1916 loss is 0.6645888090133667\n",
            "for epoch 1917 loss is 0.6645855903625488\n",
            "for epoch 1918 loss is 0.6645823121070862\n",
            "for epoch 1919 loss is 0.6645790934562683\n",
            "for epoch 1920 loss is 0.6645757555961609\n",
            "for epoch 1921 loss is 0.664572536945343\n",
            "for epoch 1922 loss is 0.6645692586898804\n",
            "for epoch 1923 loss is 0.6645660996437073\n",
            "for epoch 1924 loss is 0.6645628809928894\n",
            "for epoch 1925 loss is 0.6645596027374268\n",
            "for epoch 1926 loss is 0.6645562648773193\n",
            "for epoch 1927 loss is 0.6645531058311462\n",
            "for epoch 1928 loss is 0.6645497679710388\n",
            "for epoch 1929 loss is 0.6645467281341553\n",
            "for epoch 1930 loss is 0.6645433902740479\n",
            "for epoch 1931 loss is 0.6645402312278748\n",
            "for epoch 1932 loss is 0.6645370721817017\n",
            "for epoch 1933 loss is 0.664533793926239\n",
            "for epoch 1934 loss is 0.6645305752754211\n",
            "for epoch 1935 loss is 0.6645273566246033\n",
            "for epoch 1936 loss is 0.6645241975784302\n",
            "for epoch 1937 loss is 0.6645210385322571\n",
            "for epoch 1938 loss is 0.664517879486084\n",
            "for epoch 1939 loss is 0.6645146012306213\n",
            "for epoch 1940 loss is 0.6645114421844482\n",
            "for epoch 1941 loss is 0.6645082235336304\n",
            "for epoch 1942 loss is 0.664505124092102\n",
            "for epoch 1943 loss is 0.6645018458366394\n",
            "for epoch 1944 loss is 0.6644988059997559\n",
            "for epoch 1945 loss is 0.664495587348938\n",
            "for epoch 1946 loss is 0.6644924283027649\n",
            "for epoch 1947 loss is 0.6644892692565918\n",
            "for epoch 1948 loss is 0.6644861102104187\n",
            "for epoch 1949 loss is 0.6644829511642456\n",
            "for epoch 1950 loss is 0.6644798517227173\n",
            "for epoch 1951 loss is 0.664476752281189\n",
            "for epoch 1952 loss is 0.6644736528396606\n",
            "for epoch 1953 loss is 0.664470374584198\n",
            "for epoch 1954 loss is 0.6644672751426697\n",
            "for epoch 1955 loss is 0.6644641160964966\n",
            "for epoch 1956 loss is 0.6644611358642578\n",
            "for epoch 1957 loss is 0.6644579172134399\n",
            "for epoch 1958 loss is 0.6644548773765564\n",
            "for epoch 1959 loss is 0.6644516587257385\n",
            "for epoch 1960 loss is 0.6644485592842102\n",
            "for epoch 1961 loss is 0.6644455194473267\n",
            "for epoch 1962 loss is 0.6644424200057983\n",
            "for epoch 1963 loss is 0.66443932056427\n",
            "for epoch 1964 loss is 0.6644362211227417\n",
            "for epoch 1965 loss is 0.6644331216812134\n",
            "for epoch 1966 loss is 0.6644300222396851\n",
            "for epoch 1967 loss is 0.6644269824028015\n",
            "for epoch 1968 loss is 0.6644238233566284\n",
            "for epoch 1969 loss is 0.6644207239151001\n",
            "for epoch 1970 loss is 0.6644177436828613\n",
            "for epoch 1971 loss is 0.664414644241333\n",
            "for epoch 1972 loss is 0.6644115447998047\n",
            "for epoch 1973 loss is 0.6644085049629211\n",
            "for epoch 1974 loss is 0.6644054651260376\n",
            "for epoch 1975 loss is 0.6644024848937988\n",
            "for epoch 1976 loss is 0.6643993854522705\n",
            "for epoch 1977 loss is 0.664396345615387\n",
            "for epoch 1978 loss is 0.6643932461738586\n",
            "for epoch 1979 loss is 0.6643901467323303\n",
            "for epoch 1980 loss is 0.6643871665000916\n",
            "for epoch 1981 loss is 0.664384126663208\n",
            "for epoch 1982 loss is 0.664381206035614\n",
            "for epoch 1983 loss is 0.6643781065940857\n",
            "for epoch 1984 loss is 0.6643750667572021\n",
            "for epoch 1985 loss is 0.6643720269203186\n",
            "for epoch 1986 loss is 0.6643690466880798\n",
            "for epoch 1987 loss is 0.6643660068511963\n",
            "for epoch 1988 loss is 0.6643630266189575\n",
            "for epoch 1989 loss is 0.664359986782074\n",
            "for epoch 1990 loss is 0.6643569469451904\n",
            "for epoch 1991 loss is 0.6643540263175964\n",
            "for epoch 1992 loss is 0.6643509268760681\n",
            "for epoch 1993 loss is 0.6643480062484741\n",
            "for epoch 1994 loss is 0.6643450260162354\n",
            "for epoch 1995 loss is 0.6643420457839966\n",
            "for epoch 1996 loss is 0.6643390655517578\n",
            "for epoch 1997 loss is 0.6643361449241638\n",
            "for epoch 1998 loss is 0.664333164691925\n",
            "for epoch 1999 loss is 0.6643301844596863\n",
            "for epoch 2000 loss is 0.6643272042274475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.weights.requires_grad, model.bias.requires_grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM7AM97kUjAr",
        "outputId": "6abe8587-85fc-4fe9-fcdb-6f7454a33bf8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation\n",
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred = (y_pred > 0.9).float()\n",
        "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
        "  print(f'Accuracy: {accuracy.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsKqqJXPVdsi",
        "outputId": "f19eea2a-445b-408f-a158-12636d697804"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6228070259094238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWJfFN-neGOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}